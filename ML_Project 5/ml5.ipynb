{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42fbec9f-ab68-48c9-84f8-08b0d4fbc32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import statsmodels as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from category_encoders import CountEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold, StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xg\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84adfe1-c5df-46a2-9918-c4b57d59fd14",
   "metadata": {},
   "source": [
    "## 1. Download data. Implement train/validation/test split function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec23d76-1172-41c2-9517-29f4bf315079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RefId</th>\n",
       "      <th>IsBadBuy</th>\n",
       "      <th>PurchDate</th>\n",
       "      <th>Auction</th>\n",
       "      <th>VehYear</th>\n",
       "      <th>VehicleAge</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Trim</th>\n",
       "      <th>SubModel</th>\n",
       "      <th>...</th>\n",
       "      <th>MMRCurrentRetailAveragePrice</th>\n",
       "      <th>MMRCurrentRetailCleanPrice</th>\n",
       "      <th>PRIMEUNIT</th>\n",
       "      <th>AUCGUART</th>\n",
       "      <th>BYRNO</th>\n",
       "      <th>VNZIP1</th>\n",
       "      <th>VNST</th>\n",
       "      <th>VehBCost</th>\n",
       "      <th>IsOnlineSale</th>\n",
       "      <th>WarrantyCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>MAZDA</td>\n",
       "      <td>MAZDA3</td>\n",
       "      <td>i</td>\n",
       "      <td>4D SEDAN I</td>\n",
       "      <td>...</td>\n",
       "      <td>11597.0</td>\n",
       "      <td>12409.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21973</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>7100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>1500 RAM PICKUP 2WD</td>\n",
       "      <td>ST</td>\n",
       "      <td>QUAD CAB 4.7L SLT</td>\n",
       "      <td>...</td>\n",
       "      <td>11374.0</td>\n",
       "      <td>12791.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>7600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>STRATUS V6</td>\n",
       "      <td>SXT</td>\n",
       "      <td>4D SEDAN SXT FFV</td>\n",
       "      <td>...</td>\n",
       "      <td>7146.0</td>\n",
       "      <td>8702.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>NEON</td>\n",
       "      <td>SXT</td>\n",
       "      <td>4D SEDAN</td>\n",
       "      <td>...</td>\n",
       "      <td>4375.0</td>\n",
       "      <td>5518.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FOCUS</td>\n",
       "      <td>ZX3</td>\n",
       "      <td>2D COUPE ZX3</td>\n",
       "      <td>...</td>\n",
       "      <td>6739.0</td>\n",
       "      <td>7911.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>MITSUBISHI</td>\n",
       "      <td>GALANT 4C</td>\n",
       "      <td>ES</td>\n",
       "      <td>4D SEDAN ES</td>\n",
       "      <td>...</td>\n",
       "      <td>8149.0</td>\n",
       "      <td>9451.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>KIA</td>\n",
       "      <td>SPECTRA</td>\n",
       "      <td>EX</td>\n",
       "      <td>4D SEDAN EX</td>\n",
       "      <td>...</td>\n",
       "      <td>6230.0</td>\n",
       "      <td>8603.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>FORD</td>\n",
       "      <td>TAURUS</td>\n",
       "      <td>SE</td>\n",
       "      <td>4D SEDAN SE</td>\n",
       "      <td>...</td>\n",
       "      <td>6942.0</td>\n",
       "      <td>8242.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>KIA</td>\n",
       "      <td>SPECTRA</td>\n",
       "      <td>EX</td>\n",
       "      <td>4D SEDAN EX</td>\n",
       "      <td>...</td>\n",
       "      <td>9637.0</td>\n",
       "      <td>10778.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21973</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FIVE HUNDRED</td>\n",
       "      <td>SEL</td>\n",
       "      <td>4D SEDAN SEL</td>\n",
       "      <td>...</td>\n",
       "      <td>12580.0</td>\n",
       "      <td>14845.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21973</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>7700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RefId  IsBadBuy  PurchDate Auction  VehYear  VehicleAge        Make  \\\n",
       "0      1         0  12/7/2009   ADESA     2006           3       MAZDA   \n",
       "1      2         0  12/7/2009   ADESA     2004           5       DODGE   \n",
       "2      3         0  12/7/2009   ADESA     2005           4       DODGE   \n",
       "3      4         0  12/7/2009   ADESA     2004           5       DODGE   \n",
       "4      5         0  12/7/2009   ADESA     2005           4        FORD   \n",
       "5      6         0  12/7/2009   ADESA     2004           5  MITSUBISHI   \n",
       "6      7         0  12/7/2009   ADESA     2004           5         KIA   \n",
       "7      8         0  12/7/2009   ADESA     2005           4        FORD   \n",
       "8      9         0  12/7/2009   ADESA     2007           2         KIA   \n",
       "9     10         0  12/7/2009   ADESA     2007           2        FORD   \n",
       "\n",
       "                 Model Trim           SubModel  ...  \\\n",
       "0               MAZDA3    i         4D SEDAN I  ...   \n",
       "1  1500 RAM PICKUP 2WD   ST  QUAD CAB 4.7L SLT  ...   \n",
       "2           STRATUS V6  SXT   4D SEDAN SXT FFV  ...   \n",
       "3                 NEON  SXT           4D SEDAN  ...   \n",
       "4                FOCUS  ZX3       2D COUPE ZX3  ...   \n",
       "5            GALANT 4C   ES        4D SEDAN ES  ...   \n",
       "6              SPECTRA   EX        4D SEDAN EX  ...   \n",
       "7               TAURUS   SE        4D SEDAN SE  ...   \n",
       "8              SPECTRA   EX        4D SEDAN EX  ...   \n",
       "9         FIVE HUNDRED  SEL       4D SEDAN SEL  ...   \n",
       "\n",
       "  MMRCurrentRetailAveragePrice MMRCurrentRetailCleanPrice  PRIMEUNIT AUCGUART  \\\n",
       "0                      11597.0                    12409.0        NaN      NaN   \n",
       "1                      11374.0                    12791.0        NaN      NaN   \n",
       "2                       7146.0                     8702.0        NaN      NaN   \n",
       "3                       4375.0                     5518.0        NaN      NaN   \n",
       "4                       6739.0                     7911.0        NaN      NaN   \n",
       "5                       8149.0                     9451.0        NaN      NaN   \n",
       "6                       6230.0                     8603.0        NaN      NaN   \n",
       "7                       6942.0                     8242.0        NaN      NaN   \n",
       "8                       9637.0                    10778.0        NaN      NaN   \n",
       "9                      12580.0                    14845.0        NaN      NaN   \n",
       "\n",
       "   BYRNO VNZIP1 VNST VehBCost  IsOnlineSale  WarrantyCost  \n",
       "0  21973  33619   FL   7100.0             0          1113  \n",
       "1  19638  33619   FL   7600.0             0          1053  \n",
       "2  19638  33619   FL   4900.0             0          1389  \n",
       "3  19638  33619   FL   4100.0             0           630  \n",
       "4  19638  33619   FL   4000.0             0          1020  \n",
       "5  19638  33619   FL   5600.0             0           594  \n",
       "6  19638  33619   FL   4200.0             0           533  \n",
       "7  19638  33619   FL   4500.0             0           825  \n",
       "8  21973  33619   FL   5600.0             0           482  \n",
       "9  21973  33619   FL   7700.0             0          1633  \n",
       "\n",
       "[10 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('training.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f495bc57-217b-433d-a633-1b86bc75f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='PurchDate', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1159612-dcfd-4758-bb7c-03c78c339e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_split_by_date_val(validation_date, test_date, data, date_col, inclusive=False):\n",
    "    data[date_col] = pd.to_datetime(data[date_col])\n",
    "    validation_date = pd.to_datetime(validation_date)\n",
    "    test_date = pd.to_datetime(test_date)\n",
    "    if validation_date >= test_date:\n",
    "        raise ValueError(\"validation_date should be less than test_date\")\n",
    "    if inclusive:\n",
    "        train = data[data[date_col] < validation_date]\n",
    "        validation = data[(data[date_col] >= validation_date) & (data[date_col] < test_date)]\n",
    "        test = data[data[date_col] >= test_date]\n",
    "    else:\n",
    "        train = data[data[date_col] < validation_date]\n",
    "        validation = data[(data[date_col] >= validation_date) & (data[date_col] < test_date)]\n",
    "        test = data[data[date_col] >= test_date] \n",
    "    return train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b01b56fb-341a-433d-b5f2-ef9c805d0c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2009-09-14 00:00:00')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_date=pd.to_datetime(df['PurchDate']).quantile(1/3)\n",
    "test_date=pd.to_datetime(df['PurchDate']).quantile(2/3)\n",
    "train_df, valid_df, test_df = my_split_by_date_val(validation_date,test_date,df,date_col='PurchDate',inclusive=True)\n",
    "train_df['PurchDate'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ec9817d-9814-48c6-91d7-da96aeccd901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Auction',\n",
       " 'Make',\n",
       " 'Model',\n",
       " 'Trim',\n",
       " 'SubModel',\n",
       " 'Color',\n",
       " 'Transmission',\n",
       " 'WheelType',\n",
       " 'Nationality',\n",
       " 'Size',\n",
       " 'TopThreeAmericanName',\n",
       " 'PRIMEUNIT',\n",
       " 'AUCGUART',\n",
       " 'VNST']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b164493e-d221-4179-a32e-96c5b1389b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountEncoder(cols=[&#x27;Auction&#x27;, &#x27;Make&#x27;, &#x27;Model&#x27;, &#x27;Trim&#x27;, &#x27;SubModel&#x27;, &#x27;Color&#x27;,\n",
       "                   &#x27;Transmission&#x27;, &#x27;WheelType&#x27;, &#x27;Nationality&#x27;, &#x27;Size&#x27;,\n",
       "                   &#x27;TopThreeAmericanName&#x27;, &#x27;PRIMEUNIT&#x27;, &#x27;AUCGUART&#x27;, &#x27;VNST&#x27;],\n",
       "             combine_min_nan_groups=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CountEncoder</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cols',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cols&nbsp;</td>\n",
       "            <td class=\"value\">[&#x27;Auction&#x27;, &#x27;Make&#x27;, ...]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('drop_invariant',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">drop_invariant&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">return_df&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('handle_unknown',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">handle_unknown&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;value&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('handle_missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">handle_missing&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;value&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_group_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_group_size&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('combine_min_nan_groups',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">combine_min_nan_groups&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_group_name',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_group_name&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('normalize',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">normalize&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "CountEncoder(cols=['Auction', 'Make', 'Model', 'Trim', 'SubModel', 'Color',\n",
       "                   'Transmission', 'WheelType', 'Nationality', 'Size',\n",
       "                   'TopThreeAmericanName', 'PRIMEUNIT', 'AUCGUART', 'VNST'],\n",
       "             combine_min_nan_groups=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = CountEncoder()\n",
    "encoder.fit(train_df[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5137ee33-fd00-463e-9845-2d5de4b42853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RefId</th>\n",
       "      <th>IsBadBuy</th>\n",
       "      <th>PurchDate</th>\n",
       "      <th>Auction</th>\n",
       "      <th>VehYear</th>\n",
       "      <th>VehicleAge</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Trim</th>\n",
       "      <th>SubModel</th>\n",
       "      <th>...</th>\n",
       "      <th>MMRCurrentRetailAveragePrice</th>\n",
       "      <th>MMRCurrentRetailCleanPrice</th>\n",
       "      <th>PRIMEUNIT</th>\n",
       "      <th>AUCGUART</th>\n",
       "      <th>BYRNO</th>\n",
       "      <th>VNZIP1</th>\n",
       "      <th>VNST</th>\n",
       "      <th>VehBCost</th>\n",
       "      <th>IsOnlineSale</th>\n",
       "      <th>WarrantyCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8899</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-12</td>\n",
       "      <td>14038</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>4766</td>\n",
       "      <td>166</td>\n",
       "      <td>424</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>7821.0</td>\n",
       "      <td>9413.0</td>\n",
       "      <td>24230</td>\n",
       "      <td>24230</td>\n",
       "      <td>18880</td>\n",
       "      <td>27542</td>\n",
       "      <td>2444</td>\n",
       "      <td>6900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>19212</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-12</td>\n",
       "      <td>5224</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>4250</td>\n",
       "      <td>308</td>\n",
       "      <td>3421</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>4577.0</td>\n",
       "      <td>5777.0</td>\n",
       "      <td>24230</td>\n",
       "      <td>24230</td>\n",
       "      <td>21053</td>\n",
       "      <td>95673</td>\n",
       "      <td>2547</td>\n",
       "      <td>4590.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>8886</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-12</td>\n",
       "      <td>14038</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>284</td>\n",
       "      <td>53</td>\n",
       "      <td>232</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6870.0</td>\n",
       "      <td>8754.0</td>\n",
       "      <td>24230</td>\n",
       "      <td>24230</td>\n",
       "      <td>18880</td>\n",
       "      <td>27542</td>\n",
       "      <td>2444</td>\n",
       "      <td>6100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8887</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-12</td>\n",
       "      <td>14038</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>4766</td>\n",
       "      <td>328</td>\n",
       "      <td>3421</td>\n",
       "      <td>511</td>\n",
       "      <td>...</td>\n",
       "      <td>4031.0</td>\n",
       "      <td>4996.0</td>\n",
       "      <td>24230</td>\n",
       "      <td>24230</td>\n",
       "      <td>16044</td>\n",
       "      <td>27542</td>\n",
       "      <td>2444</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>8888</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-12</td>\n",
       "      <td>14038</td>\n",
       "      <td>2003</td>\n",
       "      <td>6</td>\n",
       "      <td>319</td>\n",
       "      <td>19</td>\n",
       "      <td>2979</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>5615.0</td>\n",
       "      <td>6318.0</td>\n",
       "      <td>24230</td>\n",
       "      <td>24230</td>\n",
       "      <td>18880</td>\n",
       "      <td>27542</td>\n",
       "      <td>2444</td>\n",
       "      <td>5800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72819</th>\n",
       "      <td>27480</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-09-09</td>\n",
       "      <td>5224</td>\n",
       "      <td>2003</td>\n",
       "      <td>6</td>\n",
       "      <td>4250</td>\n",
       "      <td>128</td>\n",
       "      <td>789</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>3444.0</td>\n",
       "      <td>4560.0</td>\n",
       "      <td>24230</td>\n",
       "      <td>24230</td>\n",
       "      <td>835</td>\n",
       "      <td>85009</td>\n",
       "      <td>2449</td>\n",
       "      <td>5385.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72820</th>\n",
       "      <td>46569</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-09-09</td>\n",
       "      <td>14038</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>2760</td>\n",
       "      <td>123</td>\n",
       "      <td>711</td>\n",
       "      <td>285</td>\n",
       "      <td>...</td>\n",
       "      <td>5496.0</td>\n",
       "      <td>6489.0</td>\n",
       "      <td>24230</td>\n",
       "      <td>24230</td>\n",
       "      <td>20928</td>\n",
       "      <td>33809</td>\n",
       "      <td>3387</td>\n",
       "      <td>4910.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72821</th>\n",
       "      <td>46570</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-09-09</td>\n",
       "      <td>14038</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>1437</td>\n",
       "      <td>682</td>\n",
       "      <td>267</td>\n",
       "      <td>166</td>\n",
       "      <td>...</td>\n",
       "      <td>7222.0</td>\n",
       "      <td>8777.0</td>\n",
       "      <td>24230</td>\n",
       "      <td>24230</td>\n",
       "      <td>20928</td>\n",
       "      <td>33809</td>\n",
       "      <td>3387</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72822</th>\n",
       "      <td>46571</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-09-09</td>\n",
       "      <td>14038</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>5644</td>\n",
       "      <td>665</td>\n",
       "      <td>2979</td>\n",
       "      <td>1255</td>\n",
       "      <td>...</td>\n",
       "      <td>7683.0</td>\n",
       "      <td>8968.0</td>\n",
       "      <td>24230</td>\n",
       "      <td>24230</td>\n",
       "      <td>20928</td>\n",
       "      <td>33809</td>\n",
       "      <td>3387</td>\n",
       "      <td>8045.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72823</th>\n",
       "      <td>46567</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-09-09</td>\n",
       "      <td>14038</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>4250</td>\n",
       "      <td>331</td>\n",
       "      <td>3421</td>\n",
       "      <td>1422</td>\n",
       "      <td>...</td>\n",
       "      <td>6991.0</td>\n",
       "      <td>8069.0</td>\n",
       "      <td>24230</td>\n",
       "      <td>24230</td>\n",
       "      <td>20928</td>\n",
       "      <td>33809</td>\n",
       "      <td>3387</td>\n",
       "      <td>7545.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24232 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RefId  IsBadBuy  PurchDate  Auction  VehYear  VehicleAge  Make  Model  \\\n",
       "38      8899         0 2009-01-12    14038     2004           5  4766    166   \n",
       "39     19212         0 2009-01-12     5224     2005           4  4250    308   \n",
       "40      8886         0 2009-01-12    14038     2005           4   284     53   \n",
       "41      8887         0 2009-01-12    14038     2005           4  4766    328   \n",
       "42      8888         0 2009-01-12    14038     2003           6   319     19   \n",
       "...      ...       ...        ...      ...      ...         ...   ...    ...   \n",
       "72819  27480         1 2009-09-09     5224     2003           6  4250    128   \n",
       "72820  46569         0 2009-09-09    14038     2006           3  2760    123   \n",
       "72821  46570         0 2009-09-09    14038     2005           4  1437    682   \n",
       "72822  46571         0 2009-09-09    14038     2006           3  5644    665   \n",
       "72823  46567         1 2009-09-09    14038     2006           3  4250    331   \n",
       "\n",
       "       Trim  SubModel  ...  MMRCurrentRetailAveragePrice  \\\n",
       "38      424       160  ...                        7821.0   \n",
       "39     3421        96  ...                        4577.0   \n",
       "40      232         5  ...                        6870.0   \n",
       "41     3421       511  ...                        4031.0   \n",
       "42     2979        54  ...                        5615.0   \n",
       "...     ...       ...  ...                           ...   \n",
       "72819   789        76  ...                        3444.0   \n",
       "72820   711       285  ...                        5496.0   \n",
       "72821   267       166  ...                        7222.0   \n",
       "72822  2979      1255  ...                        7683.0   \n",
       "72823  3421      1422  ...                        6991.0   \n",
       "\n",
       "       MMRCurrentRetailCleanPrice  PRIMEUNIT  AUCGUART  BYRNO  VNZIP1  VNST  \\\n",
       "38                         9413.0      24230     24230  18880   27542  2444   \n",
       "39                         5777.0      24230     24230  21053   95673  2547   \n",
       "40                         8754.0      24230     24230  18880   27542  2444   \n",
       "41                         4996.0      24230     24230  16044   27542  2444   \n",
       "42                         6318.0      24230     24230  18880   27542  2444   \n",
       "...                           ...        ...       ...    ...     ...   ...   \n",
       "72819                      4560.0      24230     24230    835   85009  2449   \n",
       "72820                      6489.0      24230     24230  20928   33809  3387   \n",
       "72821                      8777.0      24230     24230  20928   33809  3387   \n",
       "72822                      8968.0      24230     24230  20928   33809  3387   \n",
       "72823                      8069.0      24230     24230  20928   33809  3387   \n",
       "\n",
       "       VehBCost  IsOnlineSale  WarrantyCost  \n",
       "38       6900.0             0          1763  \n",
       "39       4590.0             0          1506  \n",
       "40       6100.0             0          1155  \n",
       "41       3300.0             0          1918  \n",
       "42       5800.0             0           805  \n",
       "...         ...           ...           ...  \n",
       "72819    5385.0             0          2322  \n",
       "72820    4910.0             0          1272  \n",
       "72821    7610.0             0          1974  \n",
       "72822    8045.0             0          2152  \n",
       "72823    7545.0             0          1633  \n",
       "\n",
       "[24232 rows x 34 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=train_df.copy()\n",
    "valid_df=valid_df.copy()\n",
    "test_df=test_df.copy()\n",
    "train_df[categorical_cols]=encoder.transform(train_df[categorical_cols])\n",
    "valid_df[categorical_cols]=encoder.transform(valid_df[categorical_cols])\n",
    "test_df[categorical_cols]=encoder.transform(test_df[categorical_cols])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05c7b4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 24232 entries, 38 to 72823\n",
      "Data columns (total 34 columns):\n",
      " #   Column                             Non-Null Count  Dtype         \n",
      "---  ------                             --------------  -----         \n",
      " 0   RefId                              24232 non-null  int64         \n",
      " 1   IsBadBuy                           24232 non-null  int64         \n",
      " 2   PurchDate                          24232 non-null  datetime64[ns]\n",
      " 3   Auction                            24232 non-null  int64         \n",
      " 4   VehYear                            24232 non-null  int64         \n",
      " 5   VehicleAge                         24232 non-null  int64         \n",
      " 6   Make                               24232 non-null  int64         \n",
      " 7   Model                              24232 non-null  int64         \n",
      " 8   Trim                               24232 non-null  int64         \n",
      " 9   SubModel                           24232 non-null  int64         \n",
      " 10  Color                              24232 non-null  int64         \n",
      " 11  Transmission                       24232 non-null  int64         \n",
      " 12  WheelTypeID                        23312 non-null  float64       \n",
      " 13  WheelType                          24232 non-null  int64         \n",
      " 14  VehOdo                             24232 non-null  int64         \n",
      " 15  Nationality                        24232 non-null  int64         \n",
      " 16  Size                               24232 non-null  int64         \n",
      " 17  TopThreeAmericanName               24232 non-null  int64         \n",
      " 18  MMRAcquisitionAuctionAveragePrice  24229 non-null  float64       \n",
      " 19  MMRAcquisitionAuctionCleanPrice    24229 non-null  float64       \n",
      " 20  MMRAcquisitionRetailAveragePrice   24229 non-null  float64       \n",
      " 21  MMRAcquisitonRetailCleanPrice      24229 non-null  float64       \n",
      " 22  MMRCurrentAuctionAveragePrice      23972 non-null  float64       \n",
      " 23  MMRCurrentAuctionCleanPrice        23972 non-null  float64       \n",
      " 24  MMRCurrentRetailAveragePrice       23972 non-null  float64       \n",
      " 25  MMRCurrentRetailCleanPrice         23972 non-null  float64       \n",
      " 26  PRIMEUNIT                          24232 non-null  int64         \n",
      " 27  AUCGUART                           24232 non-null  int64         \n",
      " 28  BYRNO                              24232 non-null  int64         \n",
      " 29  VNZIP1                             24232 non-null  int64         \n",
      " 30  VNST                               24232 non-null  int64         \n",
      " 31  VehBCost                           24232 non-null  float64       \n",
      " 32  IsOnlineSale                       24232 non-null  int64         \n",
      " 33  WarrantyCost                       24232 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(10), int64(23)\n",
      "memory usage: 6.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9905ca4a-5427-4675-9519-aedf125540b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(['PurchDate', 'IsBadBuy'], axis=1).copy()\n",
    "y_train = train_df['IsBadBuy'].copy()\n",
    "X_valid = valid_df.drop(['PurchDate', 'IsBadBuy'], axis=1).copy()\n",
    "y_valid = valid_df['IsBadBuy'].copy()\n",
    "X_train=X_train.fillna(X_train.mean())\n",
    "X_valid=X_valid.fillna(X_train.mean())\n",
    "X_test=test_df.drop(['PurchDate', 'IsBadBuy'], axis=1).copy()\n",
    "y_test = test_df['IsBadBuy'].copy()\n",
    "feature_columns = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deede367",
   "metadata": {},
   "source": [
    "## 2. Implement Decision Tree Classifier and Decision Tree Regressor (MSE loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc3789e2-79be-4fd3-ae07-94369dd0200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split_clsn(self, X, y):\n",
    "    best_gini = float('inf')\n",
    "    best_feature = None\n",
    "    best_threshold = None\n",
    "    n_samples, n_features = X.shape\n",
    "    for feature_idx in range(n_features):\n",
    "        feature_values = np.unique(X[:, feature_idx])\n",
    "        for threshold in feature_values:\n",
    "            left_mask = X[:, feature_idx] <= threshold\n",
    "            right_mask = X[:, feature_idx] > threshold\n",
    "            left_y = y[left_mask]\n",
    "            right_y = y[right_mask]\n",
    "            if len(left_y) == 0 or len(right_y) == 0:\n",
    "                continue\n",
    "            left_gini = self._gini(left_y)\n",
    "            right_gini = self._gini(right_y)\n",
    "            n_left = len(left_y)\n",
    "            n_right = len(right_y)\n",
    "            total = n_left + n_right            \n",
    "            weighted_gini = (n_left / total) * left_gini + (n_right / total) * right_gini\n",
    "            if weighted_gini < best_gini:\n",
    "                best_gini = weighted_gini\n",
    "                best_feature = feature_idx\n",
    "                best_threshold = threshold\n",
    "    return best_feature, best_threshold, best_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e28d6eef-2b06-47bc-b652-e07e7a1ffd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split_rgsn(self, X, y):\n",
    "    best_mse = float('inf')\n",
    "    best_feature = None\n",
    "    best_threshold = None\n",
    "    n_samples, n_features = X.shape\n",
    "    for feature_idx in range(n_features):\n",
    "        feature_values = np.unique(X[:, feature_idx])\n",
    "        for threshold in feature_values:\n",
    "            left_mask = X[:, feature_idx] <= threshold\n",
    "            right_mask = X[:, feature_idx] > threshold\n",
    "            left_y = y[left_mask]\n",
    "            right_y = y[right_mask]\n",
    "            if len(left_y) == 0 or len(right_y) == 0:\n",
    "                continue\n",
    "            left_mse = np.var(left_y)\n",
    "            right_mse = np.var(right_y)\n",
    "            n_left = len(left_y)\n",
    "            n_right = len(right_y)\n",
    "            total = n_left + n_right\n",
    "            weighted_mse = (n_left / total) * left_mse + (n_right / total) * right_mse\n",
    "            if weighted_mse < best_mse:\n",
    "                best_mse = weighted_mse\n",
    "                best_feature = feature_idx\n",
    "                best_threshold = threshold\n",
    "    return best_feature, best_threshold, best_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2faa0dea-f049-4c9e-adfd-0eb8e9857b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None, probs=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        self.probs = probs\n",
    "    \n",
    "    def is_leaf(self):\n",
    "        return self.value is not None\n",
    "\n",
    "class my_DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=100, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "        self.n_classes_ = None\n",
    "        \n",
    "    def _gini(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        counts = np.bincount(y)\n",
    "        probs = counts / len(y)\n",
    "        return 1 - np.sum(probs ** 2)\n",
    "    \n",
    "    def _most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        return counter.most_common(1)[0][0]\n",
    "    \n",
    "    def _calculate_probs(self, y):\n",
    "        if len(y) == 0:\n",
    "            return np.zeros(self.n_classes_) if self.n_classes_ else None\n",
    "        counts = np.bincount(y, minlength=self.n_classes_)\n",
    "        probs = counts / len(y)\n",
    "        return probs\n",
    "    \n",
    "    def _find_best_split_clsn(self, X, y):\n",
    "        best_gini = float('inf')\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        n_samples, n_features = X.shape\n",
    "        for feature_idx in range(n_features):\n",
    "            feature_values = np.unique(X[:, feature_idx])\n",
    "            for threshold in feature_values:\n",
    "                left_mask = X[:, feature_idx] <= threshold\n",
    "                right_mask = X[:, feature_idx] > threshold\n",
    "                left_y = y[left_mask]\n",
    "                right_y = y[right_mask]\n",
    "                if len(left_y) == 0 or len(right_y) == 0:\n",
    "                    continue\n",
    "                left_gini = self._gini(left_y)\n",
    "                right_gini = self._gini(right_y)\n",
    "                n_left = len(left_y)\n",
    "                n_right = len(right_y)\n",
    "                total = n_left + n_right            \n",
    "                weighted_gini = (n_left / total) * left_gini + (n_right / total) * right_gini\n",
    "                if weighted_gini < best_gini:\n",
    "                    best_gini = weighted_gini\n",
    "                    best_feature = feature_idx\n",
    "                    best_threshold = threshold\n",
    "        return best_feature, best_threshold, best_gini\n",
    "    \n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        n_samples = len(y)\n",
    "        node_probs = self._calculate_probs(y)\n",
    "        if (depth >= self.max_depth or \n",
    "            n_samples < self.min_samples_split or \n",
    "            len(np.unique(y)) == 1):\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value, probs=node_probs)\n",
    "        best_feature, best_threshold, best_gini = self._find_best_split_clsn(X, y)\n",
    "        if best_feature is None:\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value, probs=node_probs)\n",
    "        left_mask = X[:, best_feature] <= best_threshold\n",
    "        right_mask = X[:, best_feature] > best_threshold\n",
    "        left_subtree = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        right_subtree = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "        return Node(\n",
    "            feature=best_feature, \n",
    "            threshold=best_threshold,\n",
    "            left=left_subtree, \n",
    "            right=right_subtree,\n",
    "            probs=node_probs\n",
    "        )\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        self.n_classes_ = len(np.unique(y))\n",
    "        self.root = self._build_tree(X, y)\n",
    "        return self\n",
    "    \n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf():\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "    \n",
    "    def _traverse_tree_proba(self, x, node):\n",
    "        if node.is_leaf():\n",
    "            return node.probs\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree_proba(x, node.left)\n",
    "        return self._traverse_tree_proba(x, node.right)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = np.array(X)\n",
    "        proba = np.array([self._traverse_tree_proba(x, self.root) for x in X])\n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1a23f06-0d6e-4d28-b0c1-7f80f5cba77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None, probs = None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        self.probs = probs\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.value is not None\n",
    "    \n",
    "class my_DecisionTreeRegressor:\n",
    "    def __init__(self, max_depth=100, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "    \n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        n_samples = len(y)\n",
    "        if (depth >= self.max_depth or \n",
    "            n_samples < self.min_samples_split):\n",
    "            leaf_value = np.mean(y)\n",
    "            return Node(value=leaf_value)\n",
    "        best_feature, best_threshold, best_mse = self._find_best_split_rgsn(X, y)\n",
    "        if best_feature is None:\n",
    "            leaf_value = np.mean(y)\n",
    "            return Node(value=leaf_value)\n",
    "        left_mask = X[:, best_feature] <= best_threshold\n",
    "        right_mask = X[:, best_feature] > best_threshold\n",
    "        left_subtree = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        right_subtree = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "        return Node(\n",
    "            feature=best_feature, \n",
    "            threshold=best_threshold,\n",
    "            left=left_subtree, \n",
    "            right=right_subtree\n",
    "        )\n",
    "\n",
    "    def _find_best_split_rgsn(self, X, y):\n",
    "        best_mse = float('inf')\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        n_samples, n_features = X.shape\n",
    "        for feature_idx in range(n_features):\n",
    "            feature_values = np.unique(X[:, feature_idx])\n",
    "            for threshold in feature_values:\n",
    "                left_mask = X[:, feature_idx] <= threshold\n",
    "                right_mask = X[:, feature_idx] > threshold\n",
    "                left_y = y[left_mask]\n",
    "                right_y = y[right_mask]\n",
    "                if len(left_y) == 0 or len(right_y) == 0:\n",
    "                    continue\n",
    "                left_mse = np.var(left_y)\n",
    "                right_mse = np.var(right_y)\n",
    "                n_left = len(left_y)\n",
    "                n_right = len(right_y)\n",
    "                total = n_left + n_right\n",
    "                weighted_mse = (n_left / total) * left_mse + (n_right / total) * right_mse\n",
    "                if weighted_mse < best_mse:\n",
    "                    best_mse = weighted_mse\n",
    "                    best_feature = feature_idx\n",
    "                    best_threshold = threshold\n",
    "        return best_feature, best_threshold, best_mse\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        self.root = self._build_tree(X, y)\n",
    "        return self\n",
    "    \n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf():\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48050b66-b23e-4cc7-9ee4-395c6bbef297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4329411995058723"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = my_DecisionTreeClassifier(max_depth=7, min_samples_split=2)\n",
    "model.fit(X_train, y_train)\n",
    "y_proba=model.predict_proba(X_valid)[:, 1]\n",
    "auc = roc_auc_score(y_valid, y_proba)\n",
    "gini = 2 * auc - 1\n",
    "gini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f0e8aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43417726062867223"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=DecisionTreeClassifier(max_depth=7, min_samples_split=2)\n",
    "model.fit(X_train, y_train)\n",
    "y_proba=model.predict_proba(X_valid)[:, 1]\n",
    "auc = roc_auc_score(y_valid, y_proba)\n",
    "gini = 2 * auc - 1\n",
    "gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b166bc",
   "metadata": {},
   "source": [
    "### Таким образом, на данной выборке моя реализация DesicionTreeClassifier работает также, как реализованный в sklearn метод с точностью до сотых. \n",
    "##### Результат объясняется тем, что в моем алгоритме используется упрощенный подход к выбору порогов разбиения, при котором рассматриваются только уникальные значения признаков, в отличие от более сложной mid-point стратегии sklearn, вычисляющей середины между соседними значениями. Это может приводить к искусственным границам, не существующим в реальных данных.\n",
    "##### Небольшое преимущество в коэффициенте gini также могло возникнуть из-за разной обработки листовых узлов и расчета вероятностей классов (sklearn использует сглаживание и взвешенное голосование)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None, probs=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        self.probs = probs\n",
    "    \n",
    "    def is_leaf(self):\n",
    "        return self.value is not None\n",
    "\n",
    "class my_DecisionTreeClassifierRand:\n",
    "    def __init__(self, max_depth=100, min_samples_split=2, random_state=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "        self.n_classes_ = None\n",
    "        self.rng = np.random.RandomState(random_state)\n",
    "        \n",
    "    def _gini(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        counts = np.bincount(y)\n",
    "        probs = counts / len(y)\n",
    "        return 1 - np.sum(probs ** 2)\n",
    "    \n",
    "    def _most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        return counter.most_common(1)[0][0]\n",
    "    \n",
    "    def _calculate_class_probs(self, y):\n",
    "        if len(y) == 0:\n",
    "            return np.zeros(self.n_classes_) if self.n_classes_ else None\n",
    "        counts = np.bincount(y, minlength=self.n_classes_)\n",
    "        probs = counts / len(y)\n",
    "        return probs\n",
    "\n",
    "    def _find_best_split_extra_random(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_random_features = max(1, int(np.sqrt(n_features)))\n",
    "        random_features = self.rng.choice(n_features, size=n_random_features, replace=False)\n",
    "        best_gini = float('inf')\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        for feature_idx in random_features:\n",
    "            feature_values = X[:, feature_idx]\n",
    "            unique_values = np.unique(feature_values)\n",
    "            if len(unique_values) <= 10:\n",
    "                candidate_thresholds = (unique_values[:-1] + unique_values[1:]) / 2\n",
    "            else:\n",
    "                n_candidates = min(50, len(unique_values) // 2)\n",
    "                candidate_thresholds = self.rng.choice(unique_values, size=n_candidates, replace=False)\n",
    "            for threshold in candidate_thresholds:\n",
    "                left_mask = X[:, feature_idx] <= threshold\n",
    "                right_mask = X[:, feature_idx] > threshold\n",
    "                if np.sum(left_mask) < 2 or np.sum(right_mask) < 2:\n",
    "                    continue\n",
    "                left_y = y[left_mask]\n",
    "                right_y = y[right_mask]\n",
    "                if len(left_y) == 0 or len(right_y) == 0:\n",
    "                    continue       \n",
    "                left_gini = self._gini(left_y)\n",
    "                right_gini = self._gini(right_y)\n",
    "                n_left = len(left_y)\n",
    "                n_right = len(right_y)\n",
    "                total = n_left + n_right            \n",
    "                weighted_gini = (n_left / total) * left_gini + (n_right / total) * right_gini\n",
    "                if weighted_gini < best_gini:\n",
    "                    best_gini = weighted_gini\n",
    "                    best_feature = feature_idx\n",
    "                    best_threshold = threshold             \n",
    "        return best_feature, best_threshold, best_gini\n",
    "    \n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        n_samples = len(y)\n",
    "        node_probs = self._calculate_class_probs(y)\n",
    "        if (depth >= self.max_depth or \n",
    "            n_samples < self.min_samples_split or \n",
    "            len(np.unique(y)) == 1):\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value, probs=node_probs)\n",
    "        best_feature, best_threshold, best_gini = self._find_best_split_extra_random(X, y)\n",
    "        if best_feature is None:\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value, probs=node_probs)\n",
    "        left_mask = X[:, best_feature] <= best_threshold\n",
    "        right_mask = X[:, best_feature] > best_threshold\n",
    "        left_subtree = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        right_subtree = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "        return Node(\n",
    "            feature=best_feature, \n",
    "            threshold=best_threshold,\n",
    "            left=left_subtree, \n",
    "            right=right_subtree,\n",
    "            probs=node_probs\n",
    "        )\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        self.n_classes_ = len(np.unique(y))\n",
    "        self.root = self._build_tree(X, y)\n",
    "        return self\n",
    "    \n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf():\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "    \n",
    "    def _traverse_tree_proba(self, x, node):\n",
    "        if node.is_leaf():\n",
    "            return node.probs\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree_proba(x, node.left)\n",
    "        return self._traverse_tree_proba(x, node.right)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = np.array(X)\n",
    "        proba = np.array([self._traverse_tree_proba(x, self.root) for x in X])\n",
    "        return proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1529427",
   "metadata": {},
   "source": [
    "## 5. Implement the RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c26cb190",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_RandomForestClassifier:\n",
    "    def __init__(self, number_of_trees=100, max_depth=10, max_features=100, min_samples_split=2, random_state=None):\n",
    "        self.number_of_trees = number_of_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.min_samples_split = min_samples_split  \n",
    "        self.trees = []\n",
    "        self.feature_indices_list = []\n",
    "        self.random_state=random_state\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        self.feature_indices_list= []\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_values = X.values\n",
    "            n_features = X.shape[1]\n",
    "        else:\n",
    "            X_values = np.array(X)\n",
    "            n_features = X_values.shape[1]   \n",
    "        y_values = np.array(y)\n",
    "        n_samples = X_values.shape[0]\n",
    "        max_features = min(self.max_features, n_features)\n",
    "        for i in range(self.number_of_trees):\n",
    "            indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "            X_bootstrap = X_values[indices]\n",
    "            y_bootstrap = y_values[indices]\n",
    "            feature_indices = np.random.choice(n_features, max_features, replace=False)\n",
    "            X_bootstrap_subset = X_bootstrap[:, feature_indices]\n",
    "            tree = my_DecisionTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split  \n",
    "            )\n",
    "            tree.fit(X_bootstrap_subset, y_bootstrap)\n",
    "            self.trees.append(tree)\n",
    "            self.feature_indices_list.append(feature_indices)\n",
    "        return self\n",
    "    def predict_proba(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_values = X.values\n",
    "        else:\n",
    "            X_values = np.array(X)   \n",
    "        all_proba = []\n",
    "        for tree, feature_indices in zip(self.trees, self.feature_indices_list):\n",
    "            X_subset = X_values[:, feature_indices]\n",
    "            tree_proba = tree.predict_proba(X_subset)\n",
    "            all_proba.append(tree_proba)\n",
    "        return np.mean(all_proba, axis=0)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return np.argmax(proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63e52061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4666587160034983"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = my_RandomForestClassifier(\n",
    "    number_of_trees=10,\n",
    "    max_depth=7,\n",
    "    random_state=21,\n",
    "    max_features=100,\n",
    "    min_samples_split=2\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "rf_proba = rf.predict_proba(X_valid)[:,1]\n",
    "auc = roc_auc_score(y_valid, rf_proba)\n",
    "gini = 2 * auc - 1\n",
    "gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0879640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4688606492013141"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier( n_estimators=10,\n",
    "    max_depth=7,\n",
    "    max_features=100, \n",
    "    min_samples_split=2,\n",
    "    random_state=21)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_proba = rf.predict_proba(X_valid)[:,1]\n",
    "auc = roc_auc_score(y_valid, rf_proba)\n",
    "gini = 2 * auc - 1\n",
    "gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8e802",
   "metadata": {},
   "source": [
    "## 6. Implement the GBDT classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fb70bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_GBDTClassifier:\n",
    "    def __init__(self, number_of_trees=100, learning_rate=0.1, max_depth=3, max_features=None, \n",
    "                 min_samples_split=2, random_state=21):\n",
    "        self.number_of_trees = number_of_trees\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.trees = []\n",
    "        self.init_predict = None\n",
    "        self.random_state=random_state\n",
    "        if random_state is not None:\n",
    "            np.random.seed(random_state)\n",
    "    \n",
    "    def _sigmoid(self, x):\n",
    "        x = np.clip(x, -10, 10)\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def _binary_cross_entropy(self, y_true, y_pred_logits):\n",
    "        probs = self._sigmoid(y_pred_logits)\n",
    "        gradients = probs - y_true\n",
    "        return gradients\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        n_samples, n_features = X.shape\n",
    "        n_pos = np.sum(y == 1)\n",
    "        n_neg = len(y) - n_pos\n",
    "        self.init_predict = np.log(n_pos / n_neg)\n",
    "        cur_predict = np.full(len(y), self.init_predict)\n",
    "        for i in range(self.number_of_trees):\n",
    "            gradients = self._binary_cross_entropy(y, cur_predict)\n",
    "            tree = DecisionTreeRegressor(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                max_features=None\n",
    "            )\n",
    "            tree.fit(X, gradients)\n",
    "            tree_predictions = tree.predict(X)\n",
    "            cur_predict -= self.learning_rate * tree_predictions\n",
    "            self.trees.append(tree)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        else:\n",
    "            X = np.array(X)\n",
    "        predictions = np.full(X.shape[0], self.init_predict)\n",
    "        for tree in self.trees:\n",
    "            tree_predictions = tree.predict(X)\n",
    "            predictions -= self.learning_rate * tree_predictions\n",
    "        probs = self._sigmoid(predictions)\n",
    "        return np.column_stack([1 - probs, probs])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return (proba[:, 1] > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac96e2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47180672590504025"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt = my_GBDTClassifier(\n",
    "    number_of_trees =100,          \n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=21\n",
    ")\n",
    "gbdt.fit(X_train, y_train)\n",
    "gbdt_proba = gbdt.predict_proba(X_valid)[:,1]\n",
    "auc = roc_auc_score(y_valid, gbdt_proba)\n",
    "gini = 2 * auc - 1\n",
    "gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7c0be6",
   "metadata": {},
   "source": [
    "## 7. Use LightGBM, Catboost, and XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22bdeea",
   "metadata": {},
   "source": [
    "### XGBoost (eXtreme Gradient Boosting)\n",
    "### Суть: Реализация градиентного бустинга с акцентом на регуляризацию и эффективность.\n",
    "Ключевые характеристики:\n",
    "- Деревья строятся горизонтально. На каждом уровне рассматриваются все возможные разделения одновременно.\n",
    "- Взвешенный квантильный эскиз для поиска разделений. Это алгоритм, который вместо перебора всех значений признака выбирает небольшое количество разделителей, аппроксимируя взвешенное распределение данных с гарантированной точностью.\n",
    "### Основные параметры:\n",
    "learning_rate, max_depth, lambda/alpha, subsample(доля строк), colsample_bytree(доля признаков для каждого дерева), n_estimators\n",
    "### Особенности:\n",
    "- Требует кодирования категорий\n",
    "- Медленнее на больших данных\n",
    "- Автоматическая обработка пропущенных значений\n",
    "### DART (Dropouts meet Multiple Additive Regression Trees) — это специальный режим работы XGBoost, который применяет технику временного исключения из нейронных сетей к алгоритму градиентного бустинга.\n",
    "Суть:\n",
    "В обычном XGBoost каждое новое дерево учится исправлять ошибки всех предыдущих деревьев. Это может привести к переобучению на шумных данных и несбалансированному вкладу деревьев. На каждой итерации DART случайно исключает часть ранее построенных деревьев из ансамбля перед обучением нового дерева."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ba31a5",
   "metadata": {},
   "source": [
    "### LightGBM (Light Gradient Boosting Machine)\n",
    "### Суть: Реализация градиентного бустинга с акцентом на скорость и эффективное использование памяти.\n",
    "Ключевые характеристики:\n",
    "- Дерево растет асимметрично, выбирая на каждом шаге лист с максимальным уменьшением потерь\n",
    "- Сохраняет объекты с большими градиентами и случайную выборку объектов с малыми градиентами\n",
    "— Объединяет взаимно исключающие признаки для уменьшения размерности\n",
    "### Основные параметры: \n",
    "num_leaves, learning_rate, max_depth, min_data_in_leaf (минимальное количество данных в листе),feature_fraction(доля признаков для итерации), bagging_fraction(доля данных для  бутстрэп-агрегирования), lambda_l1/lambda_l2\n",
    "### Особенности:\n",
    "- Высокая скорость обучения\n",
    "- Низкое потребление памяти\n",
    "- Поддержка категориальных признаков без предварительного кодирования\n",
    "- Риск переобучения на малых данных\n",
    "### Linear Tree — это особенность LightGBM, которая вместо константных значений в листьях деревьев использует линейные модели (обычно линейную регрессию).\n",
    "### Суть:\n",
    "- В каждом листовом узле строится простая линейная модель на основе признаков, которые попали в этот лист\n",
    "- Вместо простого усреднения целевых значений в листе используется линейная комбинация признаков\n",
    "- Веса линейной модели обучаются градиентным спуском\n",
    "\n",
    "Преимущества:\n",
    "- Лучше работает с данными, имеющими линейные зависимости\n",
    "- Может уменьшить количество необходимых деревьев\n",
    "- Более точные предсказания на гладких функциях\n",
    "\n",
    "Недостатки:\n",
    "- Увеличивает риск переобучения\n",
    "- Требует больше вычислительных ресурсов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0700a841",
   "metadata": {},
   "source": [
    "### CatBoost (Categorical Boosting)\n",
    "### Суть: Реализация градиентного бустинга с продвинутой обработкой категориальных признаков и защитой от переобучения.\n",
    "Ключевые характеристики:\n",
    "- Ordered Boosting — модификация алгоритма бустинга, устраняющая смещение предсказаний\n",
    "- Симметричные деревья и одинаковые разделения на каждом уровне для эффективности вычислений (все узлы на одном уровне дерева используют одинаковые признаки и пороги для разделения)\n",
    "- Автоматическая обработка категориальных признаков — встроенные механизмы работы с категориальными признаками\n",
    "Основные параметры:\n",
    "iterations, learning_rate, depth, l2_leaf_reg, random_strength, cat_features\n",
    "### Особенности:\n",
    "- Устойчивость к переобучению\n",
    "- Низкая скорость обучения по сравнению с LightGBM\n",
    "- Полное исключение утечек данных\n",
    "- Автоматизация предобработки данных\n",
    "### Ordered Target Encoding — это специальный алгоритм в CatBoost, который предотвращает переобучение при работе с категориальными признаками.\n",
    "### Суть:\n",
    "В стандартном Target Encoding статистика по категориям вычисляется по всей выборке, что приводит к утечкам. CatBoost решает эту проблему через Ordered Target Encoding, основанный на принципе временных рядов. Создается случайный порядок объектов, а затем для каждого объекта i вычисляется encoding только на основе объектов 1...(i-1). Процесс повторяется для нескольких случайных порядков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "183c9ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6920783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "        'random_strength': trial.suggest_float('random_strength', 0.1, 10),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', \n",
    "                        ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 100),\n",
    "        'rsm': trial.suggest_float('rsm', 0.5, 1.0),\n",
    "        'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations', 1, 10),\n",
    "        'random_seed':21,\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'AUC',\n",
    "        'verbose':False\n",
    "    }\n",
    "    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_proba=model.predict_proba(X_valid)[:,1]\n",
    "    auc = roc_auc_score(y_valid, y_proba)\n",
    "    gini = 2 * auc - 1\n",
    "    return gini\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2595d33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 20:51:52,140] A new study created in memory with name: no-name-5939db32-31ba-41c0-9f76-7c7ce647d0a5\n",
      "[I 2025-11-10 20:51:55,390] Trial 0 finished with value: 0.4165792983717753 and parameters: {'iterations': 812, 'learning_rate': 0.09232455172491126, 'l2_leaf_reg': 6.08039649440209, 'random_strength': 2.1850996214163723, 'border_count': 250, 'bagging_temperature': 0.22637070930510406, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 46, 'rsm': 0.5680671208463406, 'leaf_estimation_iterations': 9}. Best is trial 0 with value: 0.4165792983717753.\n",
      "[I 2025-11-10 20:51:56,479] Trial 1 finished with value: 0.4855348215313451 and parameters: {'iterations': 503, 'learning_rate': 0.013745290980599864, 'l2_leaf_reg': 8.913931147114225, 'random_strength': 5.615408640722761, 'border_count': 206, 'bagging_temperature': 0.5797879218630412, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 31, 'rsm': 0.9687304460718158, 'leaf_estimation_iterations': 7}. Best is trial 1 with value: 0.4855348215313451.\n",
      "[I 2025-11-10 20:51:56,717] Trial 2 finished with value: 0.4870777396857944 and parameters: {'iterations': 120, 'learning_rate': 0.09855805570029344, 'l2_leaf_reg': 7.761037691691558, 'random_strength': 4.348189330759356, 'border_count': 58, 'bagging_temperature': 0.7913544345968523, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 99, 'rsm': 0.8506176807876631, 'leaf_estimation_iterations': 4}. Best is trial 2 with value: 0.4870777396857944.\n",
      "[I 2025-11-10 20:51:58,218] Trial 3 finished with value: 0.44152152256386357 and parameters: {'iterations': 654, 'learning_rate': 0.10710080703900025, 'l2_leaf_reg': 5.355844750971336, 'random_strength': 9.284540911432554, 'border_count': 144, 'bagging_temperature': 0.1351972782809372, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 45, 'rsm': 0.9942937435366627, 'leaf_estimation_iterations': 9}. Best is trial 2 with value: 0.4870777396857944.\n",
      "[I 2025-11-10 20:52:01,244] Trial 4 finished with value: 0.40666367923464786 and parameters: {'iterations': 794, 'learning_rate': 0.2909878526833408, 'l2_leaf_reg': 8.288928721946542, 'random_strength': 2.1224221508690486, 'border_count': 54, 'bagging_temperature': 0.4153191322573996, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 74, 'rsm': 0.8800201547295745, 'leaf_estimation_iterations': 7}. Best is trial 2 with value: 0.4870777396857944.\n",
      "[I 2025-11-10 20:52:02,857] Trial 5 finished with value: 0.48643455180213024 and parameters: {'iterations': 441, 'learning_rate': 0.01461755787916045, 'l2_leaf_reg': 6.114843470140625, 'random_strength': 7.731079337307892, 'border_count': 221, 'bagging_temperature': 0.7044824247158525, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 89, 'rsm': 0.7534001409539679, 'leaf_estimation_iterations': 4}. Best is trial 2 with value: 0.4870777396857944.\n",
      "[I 2025-11-10 20:52:04,963] Trial 6 finished with value: 0.48802830376754636 and parameters: {'iterations': 538, 'learning_rate': 0.011467539555474679, 'l2_leaf_reg': 4.822438601321659, 'random_strength': 2.992002148289478, 'border_count': 146, 'bagging_temperature': 0.345596537228402, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 32, 'rsm': 0.7037027886768836, 'leaf_estimation_iterations': 8}. Best is trial 6 with value: 0.48802830376754636.\n",
      "[I 2025-11-10 20:52:06,094] Trial 7 finished with value: 0.43256987683592074 and parameters: {'iterations': 642, 'learning_rate': 0.1530493125573176, 'l2_leaf_reg': 2.9235611001929156, 'random_strength': 2.79584888779532, 'border_count': 97, 'bagging_temperature': 0.9856208783428987, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 40, 'rsm': 0.8206921591371801, 'leaf_estimation_iterations': 3}. Best is trial 6 with value: 0.48802830376754636.\n",
      "[I 2025-11-10 20:52:07,706] Trial 8 finished with value: 0.4670385233363832 and parameters: {'iterations': 435, 'learning_rate': 0.050079450580386334, 'l2_leaf_reg': 3.2852485379840988, 'random_strength': 3.8295558893561252, 'border_count': 243, 'bagging_temperature': 0.26825200490090473, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 31, 'rsm': 0.6305424077234931, 'leaf_estimation_iterations': 8}. Best is trial 6 with value: 0.48802830376754636.\n",
      "[I 2025-11-10 20:52:09,068] Trial 9 finished with value: 0.4724957191018835 and parameters: {'iterations': 433, 'learning_rate': 0.05088561485153991, 'l2_leaf_reg': 4.051711021068236, 'random_strength': 3.765799686797833, 'border_count': 35, 'bagging_temperature': 0.3968197182943791, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 8, 'rsm': 0.5242531618781416, 'leaf_estimation_iterations': 4}. Best is trial 6 with value: 0.48802830376754636.\n",
      "[I 2025-11-10 20:52:09,730] Trial 10 finished with value: 0.4943619859807262 and parameters: {'iterations': 205, 'learning_rate': 0.02118855692020578, 'l2_leaf_reg': 1.7604599680528326, 'random_strength': 0.23089409337575706, 'border_count': 165, 'bagging_temperature': 0.0041008397989352185, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 2, 'rsm': 0.6611682869108998, 'leaf_estimation_iterations': 1}. Best is trial 10 with value: 0.4943619859807262.\n",
      "[I 2025-11-10 20:52:10,399] Trial 11 finished with value: 0.4905695048160845 and parameters: {'iterations': 210, 'learning_rate': 0.024270929169177398, 'l2_leaf_reg': 1.3711689523247177, 'random_strength': 0.8408014202088134, 'border_count': 159, 'bagging_temperature': 0.0172520289110224, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 2, 'rsm': 0.6668655902380078, 'leaf_estimation_iterations': 1}. Best is trial 10 with value: 0.4943619859807262.\n",
      "[I 2025-11-10 20:52:10,907] Trial 12 finished with value: 0.49423231303778214 and parameters: {'iterations': 149, 'learning_rate': 0.024589619751838765, 'l2_leaf_reg': 1.7847382478295035, 'random_strength': 0.23021322518197995, 'border_count': 182, 'bagging_temperature': 0.013459864689765455, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 1, 'rsm': 0.6599371133104689, 'leaf_estimation_iterations': 1}. Best is trial 10 with value: 0.4943619859807262.\n",
      "[I 2025-11-10 20:52:11,657] Trial 13 finished with value: 0.49861771194154003 and parameters: {'iterations': 249, 'learning_rate': 0.023171138091832723, 'l2_leaf_reg': 1.2261223663669902, 'random_strength': 0.10036393424448242, 'border_count': 189, 'bagging_temperature': 0.046254459917762114, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 14, 'rsm': 0.5948181132082014, 'leaf_estimation_iterations': 1}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:12,578] Trial 14 finished with value: 0.49003675105049593 and parameters: {'iterations': 300, 'learning_rate': 0.027268696604419333, 'l2_leaf_reg': 1.186325841736032, 'random_strength': 1.0907878312167205, 'border_count': 108, 'bagging_temperature': 0.15514785935773096, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 16, 'rsm': 0.5924423665477456, 'leaf_estimation_iterations': 2}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:13,455] Trial 15 finished with value: 0.4877352268965003 and parameters: {'iterations': 295, 'learning_rate': 0.03415328542248052, 'l2_leaf_reg': 2.391222097102932, 'random_strength': 5.890608737751099, 'border_count': 182, 'bagging_temperature': 0.005366878921475263, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 17, 'rsm': 0.5097700950922707, 'leaf_estimation_iterations': 2}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:14,474] Trial 16 finished with value: 0.4926928807151325 and parameters: {'iterations': 291, 'learning_rate': 0.017358741139015383, 'l2_leaf_reg': 9.983746609414442, 'random_strength': 1.3647730184451006, 'border_count': 109, 'bagging_temperature': 0.14421857368378338, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 19, 'rsm': 0.7301392143260774, 'leaf_estimation_iterations': 5}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:17,635] Trial 17 finished with value: 0.4878697503373097 and parameters: {'iterations': 984, 'learning_rate': 0.01010917016566217, 'l2_leaf_reg': 3.893868811235531, 'random_strength': 7.03448378439923, 'border_count': 181, 'bagging_temperature': 0.5425176803443099, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 65, 'rsm': 0.7819920903476949, 'leaf_estimation_iterations': 2}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:18,267] Trial 18 finished with value: 0.4956631802415341 and parameters: {'iterations': 224, 'learning_rate': 0.036955062036683785, 'l2_leaf_reg': 2.2837771747411426, 'random_strength': 0.5862612162287453, 'border_count': 210, 'bagging_temperature': 0.26670422327192606, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 58, 'rsm': 0.5863572184399573, 'leaf_estimation_iterations': 1}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:19,330] Trial 19 finished with value: 0.4840748958403793 and parameters: {'iterations': 349, 'learning_rate': 0.04300507737796989, 'l2_leaf_reg': 2.6435542076944576, 'random_strength': 1.646194808725283, 'border_count': 214, 'bagging_temperature': 0.30425349686766856, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 61, 'rsm': 0.573089739090284, 'leaf_estimation_iterations': 3}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:19,714] Trial 20 finished with value: 0.48041940044879716 and parameters: {'iterations': 104, 'learning_rate': 0.03503191598278355, 'l2_leaf_reg': 3.7372023533882968, 'random_strength': 4.6303747226596395, 'border_count': 226, 'bagging_temperature': 0.46603375078256587, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 57, 'rsm': 0.6141763257934376, 'leaf_estimation_iterations': 6}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:20,392] Trial 21 finished with value: 0.4908690341842914 and parameters: {'iterations': 214, 'learning_rate': 0.01897759114081339, 'l2_leaf_reg': 2.0220780909969505, 'random_strength': 0.6010826252042369, 'border_count': 194, 'bagging_temperature': 0.10273450832951361, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 74, 'rsm': 0.6785624987296742, 'leaf_estimation_iterations': 1}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:20,996] Trial 22 finished with value: 0.4934351255552114 and parameters: {'iterations': 198, 'learning_rate': 0.020100702650038303, 'l2_leaf_reg': 1.3633554334955251, 'random_strength': 0.4151990783136868, 'border_count': 163, 'bagging_temperature': 0.21493227689979072, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 11, 'rsm': 0.5461699478494622, 'leaf_estimation_iterations': 1}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:22,138] Trial 23 finished with value: 0.4806907316627449 and parameters: {'iterations': 356, 'learning_rate': 0.032507084647302696, 'l2_leaf_reg': 2.265674462251212, 'random_strength': 0.22829529402623966, 'border_count': 122, 'bagging_temperature': 0.07536245962203847, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 25, 'rsm': 0.6315544911609772, 'leaf_estimation_iterations': 3}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:22,898] Trial 24 finished with value: 0.48372128416263505 and parameters: {'iterations': 238, 'learning_rate': 0.07028217582659822, 'l2_leaf_reg': 1.099688002457079, 'random_strength': 1.89153373099818, 'border_count': 166, 'bagging_temperature': 0.19779502245250177, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 73, 'rsm': 0.5942223583477071, 'leaf_estimation_iterations': 2}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:23,973] Trial 25 finished with value: 0.48360818004573414 and parameters: {'iterations': 350, 'learning_rate': 0.06699992556711011, 'l2_leaf_reg': 3.1761983248607066, 'random_strength': 2.9658438809643637, 'border_count': 202, 'bagging_temperature': 0.07580163767233639, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 52, 'rsm': 0.6950152358312895, 'leaf_estimation_iterations': 1}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:24,540] Trial 26 finished with value: 0.49040184372318874 and parameters: {'iterations': 172, 'learning_rate': 0.02654788411865994, 'l2_leaf_reg': 4.368974691223181, 'random_strength': 1.1969299595994327, 'border_count': 235, 'bagging_temperature': 0.30555747883886153, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 38, 'rsm': 0.501604831371837, 'leaf_estimation_iterations': 3}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:25,462] Trial 27 finished with value: 0.49625424381479943 and parameters: {'iterations': 260, 'learning_rate': 0.014907547034348769, 'l2_leaf_reg': 1.9554881000773836, 'random_strength': 0.17788214488916787, 'border_count': 195, 'bagging_temperature': 0.07083089846086506, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 7, 'rsm': 0.62912786328947, 'leaf_estimation_iterations': 2}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:25,940] Trial 28 finished with value: 0.48086273892039477 and parameters: {'iterations': 276, 'learning_rate': 0.015349835750502009, 'l2_leaf_reg': 2.706616597865107, 'random_strength': 2.5303266152104564, 'border_count': 194, 'bagging_temperature': 0.23017743757339656, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 22, 'rsm': 0.5510600762416, 'leaf_estimation_iterations': 2}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:27,947] Trial 29 finished with value: 0.47197443149791685 and parameters: {'iterations': 600, 'learning_rate': 0.039771103919924396, 'l2_leaf_reg': 6.766305939619064, 'random_strength': 1.7689591184299007, 'border_count': 252, 'bagging_temperature': 0.23115189715684753, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 47, 'rsm': 0.5791656804060727, 'leaf_estimation_iterations': 5}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:29,242] Trial 30 finished with value: 0.47691953632207085 and parameters: {'iterations': 387, 'learning_rate': 0.011291057267760682, 'l2_leaf_reg': 3.4443329296669036, 'random_strength': 9.394791589541487, 'border_count': 227, 'bagging_temperature': 0.07979992309198476, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 9, 'rsm': 0.6278595373997286, 'leaf_estimation_iterations': 2}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:29,763] Trial 31 finished with value: 0.48603112981296936 and parameters: {'iterations': 154, 'learning_rate': 0.020224387928418276, 'l2_leaf_reg': 1.8175511428975801, 'random_strength': 0.9221409757048153, 'border_count': 178, 'bagging_temperature': 0.047007304147255576, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 6, 'rsm': 0.656343077839007, 'leaf_estimation_iterations': 1}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:30,518] Trial 32 finished with value: 0.492967134094461 and parameters: {'iterations': 249, 'learning_rate': 0.013753533690094504, 'l2_leaf_reg': 1.0101588481471582, 'random_strength': 0.16937202660381842, 'border_count': 204, 'bagging_temperature': 0.15844175301615412, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 15, 'rsm': 0.5433524818879288, 'leaf_estimation_iterations': 1}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:31,917] Trial 33 finished with value: 0.4868183641332531 and parameters: {'iterations': 318, 'learning_rate': 0.028270015413824533, 'l2_leaf_reg': 1.756581477827124, 'random_strength': 0.1265097149982786, 'border_count': 129, 'bagging_temperature': 0.00024778042276165247, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 2, 'rsm': 0.7200185766613667, 'leaf_estimation_iterations': 10}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:32,110] Trial 34 finished with value: 0.4809205147283069 and parameters: {'iterations': 106, 'learning_rate': 0.022073940375761603, 'l2_leaf_reg': 2.3425936285037245, 'random_strength': 1.2916837641511383, 'border_count': 152, 'bagging_temperature': 0.12042687161144534, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 26, 'rsm': 0.6220528753698499, 'leaf_estimation_iterations': 2}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:33,758] Trial 35 finished with value: 0.4882027140241392 and parameters: {'iterations': 507, 'learning_rate': 0.0176725024551483, 'l2_leaf_reg': 1.694476732257654, 'random_strength': 2.0889918445168076, 'border_count': 169, 'bagging_temperature': 0.607177118808168, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 12, 'rsm': 0.5981150226671189, 'leaf_estimation_iterations': 3}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:34,887] Trial 36 finished with value: 0.49069566226057515 and parameters: {'iterations': 772, 'learning_rate': 0.015662608716172657, 'l2_leaf_reg': 4.800415614163649, 'random_strength': 0.786319329674947, 'border_count': 214, 'bagging_temperature': 0.16340890039063616, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 85, 'rsm': 0.9449209405233044, 'leaf_estimation_iterations': 1}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:36,300] Trial 37 finished with value: 0.4837109750005042 and parameters: {'iterations': 397, 'learning_rate': 0.012136991271881975, 'l2_leaf_reg': 6.00506080562127, 'random_strength': 5.601266735328206, 'border_count': 193, 'bagging_temperature': 0.06436501015103194, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 38, 'rsm': 0.7576534131920918, 'leaf_estimation_iterations': 4}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:37,128] Trial 38 finished with value: 0.48594815218281306 and parameters: {'iterations': 247, 'learning_rate': 0.06285828812936269, 'l2_leaf_reg': 7.661269523057047, 'random_strength': 8.017731710686057, 'border_count': 134, 'bagging_temperature': 0.3961376028354151, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 6, 'rsm': 0.6409660254937957, 'leaf_estimation_iterations': 2}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:38,685] Trial 39 finished with value: 0.44834701856064507 and parameters: {'iterations': 481, 'learning_rate': 0.08935989854319129, 'l2_leaf_reg': 2.661327272353602, 'random_strength': 3.481349676489221, 'border_count': 173, 'bagging_temperature': 0.9057588186561517, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 68, 'rsm': 0.5555786349481207, 'leaf_estimation_iterations': 4}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:39,027] Trial 40 finished with value: 0.46608591225553164 and parameters: {'iterations': 180, 'learning_rate': 0.16998732991845114, 'l2_leaf_reg': 3.204059242636868, 'random_strength': 2.3473944505587947, 'border_count': 74, 'bagging_temperature': 0.3266630131682419, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 30, 'rsm': 0.6943134376998786, 'leaf_estimation_iterations': 3}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:39,517] Trial 41 finished with value: 0.492633146908082 and parameters: {'iterations': 140, 'learning_rate': 0.02340321485984666, 'l2_leaf_reg': 1.6717361002910325, 'random_strength': 0.11168839726567217, 'border_count': 188, 'bagging_temperature': 0.03270073321305237, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 1, 'rsm': 0.6646012856001025, 'leaf_estimation_iterations': 1}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:40,044] Trial 42 finished with value: 0.48871020663417575 and parameters: {'iterations': 157, 'learning_rate': 0.029740052665870726, 'l2_leaf_reg': 2.128759103779538, 'random_strength': 0.6753169964624868, 'border_count': 209, 'bagging_temperature': 0.11178604120631815, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 5, 'rsm': 0.6066538012826115, 'leaf_estimation_iterations': 1}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:40,757] Trial 43 finished with value: 0.4891253469515138 and parameters: {'iterations': 240, 'learning_rate': 0.04140155536721168, 'l2_leaf_reg': 1.5209536287170102, 'random_strength': 1.5149490539642902, 'border_count': 155, 'bagging_temperature': 0.18616657194273933, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 13, 'rsm': 0.651352860847918, 'leaf_estimation_iterations': 1}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:41,424] Trial 44 finished with value: 0.4931697128386596 and parameters: {'iterations': 188, 'learning_rate': 0.024530403591653985, 'l2_leaf_reg': 2.017526410910545, 'random_strength': 0.6947912605991462, 'border_count': 200, 'bagging_temperature': 0.2547921877568528, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 22, 'rsm': 0.7841175379089642, 'leaf_estimation_iterations': 2}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:43,828] Trial 45 finished with value: 0.49296711926113423 and parameters: {'iterations': 723, 'learning_rate': 0.012949733216679315, 'l2_leaf_reg': 3.0011781603840157, 'random_strength': 0.9553885710233878, 'border_count': 139, 'bagging_temperature': 0.026926328018560652, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 1, 'rsm': 0.6815368402150443, 'leaf_estimation_iterations': 1}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:44,414] Trial 46 finished with value: 0.48509637805759365 and parameters: {'iterations': 137, 'learning_rate': 0.01669495527761012, 'l2_leaf_reg': 1.4347144734228647, 'random_strength': 1.3788915906478982, 'border_count': 242, 'bagging_temperature': 0.684498788397927, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 8, 'rsm': 0.7212520680465863, 'leaf_estimation_iterations': 7}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:47,032] Trial 47 finished with value: 0.48190501746179226 and parameters: {'iterations': 878, 'learning_rate': 0.021381641124511817, 'l2_leaf_reg': 1.0126402619091774, 'random_strength': 0.48266219159469026, 'border_count': 185, 'bagging_temperature': 0.0020683395349600266, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 19, 'rsm': 0.5294959770780703, 'leaf_estimation_iterations': 2}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:47,860] Trial 48 finished with value: 0.4888416299096825 and parameters: {'iterations': 293, 'learning_rate': 0.04879349134624081, 'l2_leaf_reg': 2.4843937822725257, 'random_strength': 8.687550544597254, 'border_count': 217, 'bagging_temperature': 0.11928278018837281, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 57, 'rsm': 0.5760429538591639, 'leaf_estimation_iterations': 1}. Best is trial 13 with value: 0.49861771194154003.\n",
      "[I 2025-11-10 20:52:49,060] Trial 49 finished with value: 0.48671469401220113 and parameters: {'iterations': 329, 'learning_rate': 0.035930703139452756, 'l2_leaf_reg': 4.227588324414157, 'random_strength': 6.700166644502429, 'border_count': 147, 'bagging_temperature': 0.059166143242425306, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 80, 'rsm': 0.8292158819450219, 'leaf_estimation_iterations': 2}. Best is trial 13 with value: 0.49861771194154003.\n"
     ]
    }
   ],
   "source": [
    "study1 = optuna.create_study(direction='maximize')\n",
    "study1.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2106e5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49861771194154003"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study1.best_trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc2deab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_study1 = study1.best_params\n",
    "best_params_study1.update({'random_seed':21,'loss_function': 'Logloss','eval_metric': 'AUC','verbose':False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec458345",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CatBoostClassifier(**best_params_study1)\n",
    "model.fit(X_train,y_train)\n",
    "y_proba_train = model.predict_proba(X_train)[:, 1]\n",
    "y_proba_valid = model.predict_proba(X_valid)[:, 1]\n",
    "y_proba_test=model.predict_proba(X_test)[:,1]\n",
    "gini_train = 2*roc_auc_score(y_train, y_proba_train)-1\n",
    "gini_valid = 2*roc_auc_score(y_valid, y_proba_valid)-1\n",
    "gini_test = 2*roc_auc_score(y_test, y_proba_test)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "645c8fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6534327464925409"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d7e6617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49861771194154003"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bdc0e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47458521834430045"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5a2eed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 31, 512),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 20, 200),\n",
    "        'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0.0, 1.0),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'max_bin': trial.suggest_int('max_bin', 32, 255),\n",
    "        'random_seed':21,\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'verbose': -1\n",
    "    }\n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_proba=model.predict_proba(X_valid)[:,1]\n",
    "    auc = roc_auc_score(y_valid, y_proba)\n",
    "    gini = 2 * auc - 1\n",
    "    return gini\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f0cfabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 20:53:54,473] A new study created in memory with name: no-name-54823145-5d22-40c9-ab1f-dad013a5525c\n",
      "[I 2025-11-10 20:53:57,879] Trial 0 finished with value: 0.4889578341918863 and parameters: {'n_estimators': 366, 'learning_rate': 0.010052777170948171, 'max_depth': 11, 'lambda_l1': 0.36156754387952883, 'lambda_l2': 5.237152209499805e-06, 'num_leaves': 378, 'min_data_in_leaf': 96, 'min_gain_to_split': 0.5850512136922393, 'feature_fraction': 0.6731091473859638, 'bagging_fraction': 0.5655892380135068, 'bagging_freq': 2, 'max_bin': 196}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:53:59,711] Trial 1 finished with value: 0.48419796795289427 and parameters: {'n_estimators': 216, 'learning_rate': 0.01743443112536441, 'max_depth': 8, 'lambda_l1': 3.425535378542812e-08, 'lambda_l2': 2.307162162608978e-08, 'num_leaves': 501, 'min_data_in_leaf': 35, 'min_gain_to_split': 0.029232188229225464, 'feature_fraction': 0.7562976086920417, 'bagging_fraction': 0.6370421656452658, 'bagging_freq': 2, 'max_bin': 159}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:00,245] Trial 2 finished with value: 0.4752464260582392 and parameters: {'n_estimators': 302, 'learning_rate': 0.0835356005018244, 'max_depth': 4, 'lambda_l1': 0.011335402886626478, 'lambda_l2': 0.00040735000165618415, 'num_leaves': 72, 'min_data_in_leaf': 43, 'min_gain_to_split': 0.13667343730254267, 'feature_fraction': 0.716892653974997, 'bagging_fraction': 0.7951311658077211, 'bagging_freq': 7, 'max_bin': 210}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:03,975] Trial 3 finished with value: 0.48292175301442875 and parameters: {'n_estimators': 994, 'learning_rate': 0.01010667613799836, 'max_depth': 7, 'lambda_l1': 7.069733203512967, 'lambda_l2': 3.117351214889081e-07, 'num_leaves': 54, 'min_data_in_leaf': 79, 'min_gain_to_split': 0.505628773893377, 'feature_fraction': 0.7701475756576688, 'bagging_fraction': 0.7797866709535577, 'bagging_freq': 2, 'max_bin': 188}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:06,508] Trial 4 finished with value: 0.466286992833723 and parameters: {'n_estimators': 378, 'learning_rate': 0.042501035489682475, 'max_depth': 11, 'lambda_l1': 8.387969685973484e-08, 'lambda_l2': 8.44446594047878e-06, 'num_leaves': 58, 'min_data_in_leaf': 86, 'min_gain_to_split': 0.39324285026627226, 'feature_fraction': 0.8323575177956931, 'bagging_fraction': 0.5391282656532466, 'bagging_freq': 1, 'max_bin': 184}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:07,626] Trial 5 finished with value: 0.42300336004518835 and parameters: {'n_estimators': 598, 'learning_rate': 0.20989182483910238, 'max_depth': 4, 'lambda_l1': 2.282990035726495, 'lambda_l2': 2.2585367333802595e-05, 'num_leaves': 58, 'min_data_in_leaf': 67, 'min_gain_to_split': 0.05732432792787323, 'feature_fraction': 0.8472094299599935, 'bagging_fraction': 0.8600704870162462, 'bagging_freq': 4, 'max_bin': 45}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:09,309] Trial 6 finished with value: 0.44457907171854183 and parameters: {'n_estimators': 491, 'learning_rate': 0.10801422191435274, 'max_depth': 6, 'lambda_l1': 1.4935476123575492e-06, 'lambda_l2': 0.00026123418304011236, 'num_leaves': 63, 'min_data_in_leaf': 106, 'min_gain_to_split': 0.3953317443408686, 'feature_fraction': 0.618377832478785, 'bagging_fraction': 0.8103008772642482, 'bagging_freq': 3, 'max_bin': 167}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:11,952] Trial 7 finished with value: 0.4186058719800827 and parameters: {'n_estimators': 887, 'learning_rate': 0.1763678692746752, 'max_depth': 11, 'lambda_l1': 0.0049752135394353315, 'lambda_l2': 0.22044397907824564, 'num_leaves': 441, 'min_data_in_leaf': 36, 'min_gain_to_split': 0.2938038396528976, 'feature_fraction': 0.7481559256087753, 'bagging_fraction': 0.7831533513266677, 'bagging_freq': 2, 'max_bin': 175}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:12,801] Trial 8 finished with value: 0.48187047064365984 and parameters: {'n_estimators': 934, 'learning_rate': 0.08410733616398064, 'max_depth': 6, 'lambda_l1': 9.580775139296893, 'lambda_l2': 0.0034039078221232977, 'num_leaves': 215, 'min_data_in_leaf': 65, 'min_gain_to_split': 0.902603188582105, 'feature_fraction': 0.6479591813165323, 'bagging_fraction': 0.6331603496093181, 'bagging_freq': 1, 'max_bin': 66}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:13,317] Trial 9 finished with value: 0.45890228041632986 and parameters: {'n_estimators': 482, 'learning_rate': 0.2667314403698658, 'max_depth': 12, 'lambda_l1': 3.114427578006153, 'lambda_l2': 0.4273642678452312, 'num_leaves': 115, 'min_data_in_leaf': 148, 'min_gain_to_split': 0.4177463255988235, 'feature_fraction': 0.6195340599967776, 'bagging_fraction': 0.8189107138752767, 'bagging_freq': 9, 'max_bin': 223}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:15,652] Trial 10 finished with value: 0.479945876157148 and parameters: {'n_estimators': 742, 'learning_rate': 0.030942459749491828, 'max_depth': 10, 'lambda_l1': 0.0003823447955735338, 'lambda_l2': 9.142841804196874e-07, 'num_leaves': 359, 'min_data_in_leaf': 181, 'min_gain_to_split': 0.6957609700793562, 'feature_fraction': 0.9569888618163921, 'bagging_fraction': 0.932677596376031, 'bagging_freq': 5, 'max_bin': 254}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:16,816] Trial 11 finished with value: 0.48510202955510695 and parameters: {'n_estimators': 135, 'learning_rate': 0.010814392431216293, 'max_depth': 9, 'lambda_l1': 8.52468709831905e-06, 'lambda_l2': 2.832218048431416e-08, 'num_leaves': 509, 'min_data_in_leaf': 137, 'min_gain_to_split': 0.6601722099724144, 'feature_fraction': 0.519108252588242, 'bagging_fraction': 0.6462874841659828, 'bagging_freq': 6, 'max_bin': 111}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:18,039] Trial 12 finished with value: 0.4881104358980748 and parameters: {'n_estimators': 162, 'learning_rate': 0.010502135901224193, 'max_depth': 9, 'lambda_l1': 8.00781375280567e-06, 'lambda_l2': 2.007657476591426e-08, 'num_leaves': 361, 'min_data_in_leaf': 126, 'min_gain_to_split': 0.6690410515300033, 'feature_fraction': 0.5385080082592734, 'bagging_fraction': 0.5007864792435537, 'bagging_freq': 7, 'max_bin': 109}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:19,097] Trial 13 finished with value: 0.4853063141318885 and parameters: {'n_estimators': 151, 'learning_rate': 0.019342676412084217, 'max_depth': 9, 'lambda_l1': 0.07372917850470183, 'lambda_l2': 9.368187400563537e-07, 'num_leaves': 324, 'min_data_in_leaf': 131, 'min_gain_to_split': 0.7685677367222976, 'feature_fraction': 0.5058108402251236, 'bagging_fraction': 0.5001003464883431, 'bagging_freq': 8, 'max_bin': 119}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:21,383] Trial 14 finished with value: 0.4797619132380917 and parameters: {'n_estimators': 331, 'learning_rate': 0.01986418587359353, 'max_depth': 12, 'lambda_l1': 3.3024548366210934e-05, 'lambda_l2': 1.3034306424350663e-08, 'num_leaves': 374, 'min_data_in_leaf': 174, 'min_gain_to_split': 0.9811581710883683, 'feature_fraction': 0.5668769782250298, 'bagging_fraction': 0.5573597421378735, 'bagging_freq': 10, 'max_bin': 120}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:23,508] Trial 15 finished with value: 0.48804255859460755 and parameters: {'n_estimators': 248, 'learning_rate': 0.014664256552777073, 'max_depth': 10, 'lambda_l1': 0.00023137275610517877, 'lambda_l2': 1.1443719737187635e-05, 'num_leaves': 259, 'min_data_in_leaf': 111, 'min_gain_to_split': 0.5748566042806937, 'feature_fraction': 0.6714448024998876, 'bagging_fraction': 0.6887271241229478, 'bagging_freq': 6, 'max_bin': 95}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:26,186] Trial 16 finished with value: 0.46779944333491175 and parameters: {'n_estimators': 409, 'learning_rate': 0.03012785612402687, 'max_depth': 9, 'lambda_l1': 3.5381414824067253e-07, 'lambda_l2': 0.01396770679836453, 'num_leaves': 416, 'min_data_in_leaf': 108, 'min_gain_to_split': 0.8171789647072761, 'feature_fraction': 0.5694909237838539, 'bagging_fraction': 0.5798493361216177, 'bagging_freq': 4, 'max_bin': 141}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:30,659] Trial 17 finished with value: 0.47575753800001674 and parameters: {'n_estimators': 602, 'learning_rate': 0.02631597336656289, 'max_depth': 11, 'lambda_l1': 0.0974112154945839, 'lambda_l2': 6.769285226702687, 'num_leaves': 278, 'min_data_in_leaf': 155, 'min_gain_to_split': 0.6032340558708701, 'feature_fraction': 0.5640490428063438, 'bagging_fraction': 0.7153609456238038, 'bagging_freq': 7, 'max_bin': 81}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:31,861] Trial 18 finished with value: 0.4668387925909312 and parameters: {'n_estimators': 240, 'learning_rate': 0.050918621417633425, 'max_depth': 8, 'lambda_l1': 0.00036346784886481364, 'lambda_l2': 2.0852495366238764e-07, 'num_leaves': 185, 'min_data_in_leaf': 98, 'min_gain_to_split': 0.23222231000743304, 'feature_fraction': 0.6889959493096003, 'bagging_fraction': 0.5149020621685643, 'bagging_freq': 5, 'max_bin': 141}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:35,510] Trial 19 finished with value: 0.4725406937487615 and parameters: {'n_estimators': 727, 'learning_rate': 0.013169055960732071, 'max_depth': 10, 'lambda_l1': 1.1498731314602826e-05, 'lambda_l2': 3.328985881070093e-06, 'num_leaves': 433, 'min_data_in_leaf': 200, 'min_gain_to_split': 0.7682754486456185, 'feature_fraction': 0.9821028167492388, 'bagging_fraction': 0.5914484235007654, 'bagging_freq': 8, 'max_bin': 216}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:36,088] Trial 20 finished with value: 0.48834647862754954 and parameters: {'n_estimators': 105, 'learning_rate': 0.023104252008394426, 'max_depth': 7, 'lambda_l1': 0.3733262917775878, 'lambda_l2': 7.949463983434013e-05, 'num_leaves': 313, 'min_data_in_leaf': 123, 'min_gain_to_split': 0.532097871809633, 'feature_fraction': 0.8285480704579793, 'bagging_fraction': 0.9830404708089505, 'bagging_freq': 4, 'max_bin': 240}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:36,773] Trial 21 finished with value: 0.48806698908385826 and parameters: {'n_estimators': 116, 'learning_rate': 0.010029916566473738, 'max_depth': 7, 'lambda_l1': 0.30778209357612224, 'lambda_l2': 0.00011411237252552947, 'num_leaves': 296, 'min_data_in_leaf': 125, 'min_gain_to_split': 0.5186267745058813, 'feature_fraction': 0.8463764672967189, 'bagging_fraction': 0.9891464861521699, 'bagging_freq': 4, 'max_bin': 241}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:37,450] Trial 22 finished with value: 0.4849525689542027 and parameters: {'n_estimators': 196, 'learning_rate': 0.022980532851089867, 'max_depth': 6, 'lambda_l1': 0.005048678560706462, 'lambda_l2': 0.0013658949196216747, 'num_leaves': 360, 'min_data_in_leaf': 156, 'min_gain_to_split': 0.6610827290317544, 'feature_fraction': 0.8918835399891667, 'bagging_fraction': 0.8917978684835078, 'bagging_freq': 3, 'max_bin': 205}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:38,805] Trial 23 finished with value: 0.4856631594748766 and parameters: {'n_estimators': 306, 'learning_rate': 0.014619992167563203, 'max_depth': 7, 'lambda_l1': 0.6055190320651129, 'lambda_l2': 7.355947406556087e-05, 'num_leaves': 325, 'min_data_in_leaf': 122, 'min_gain_to_split': 0.47005479858991756, 'feature_fraction': 0.9024836931507925, 'bagging_fraction': 0.7194809256430528, 'bagging_freq': 3, 'max_bin': 233}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:39,718] Trial 24 finished with value: 0.4851234637123427 and parameters: {'n_estimators': 103, 'learning_rate': 0.03700213956551248, 'max_depth': 9, 'lambda_l1': 0.04210564764621305, 'lambda_l2': 1.432605390860323e-07, 'num_leaves': 238, 'min_data_in_leaf': 90, 'min_gain_to_split': 0.5844056873307442, 'feature_fraction': 0.8120404123513394, 'bagging_fraction': 0.9808832306741612, 'bagging_freq': 7, 'max_bin': 198}. Best is trial 0 with value: 0.4889578341918863.\n",
      "[I 2025-11-10 20:54:40,647] Trial 25 finished with value: 0.48907863680539987 and parameters: {'n_estimators': 404, 'learning_rate': 0.013476632597329015, 'max_depth': 5, 'lambda_l1': 0.42688865747126425, 'lambda_l2': 1.764721146687395e-06, 'num_leaves': 396, 'min_data_in_leaf': 141, 'min_gain_to_split': 0.31547238391670984, 'feature_fraction': 0.7095412331835237, 'bagging_fraction': 0.601514841966498, 'bagging_freq': 5, 'max_bin': 252}. Best is trial 25 with value: 0.48907863680539987.\n",
      "[I 2025-11-10 20:54:41,593] Trial 26 finished with value: 0.49147146008589093 and parameters: {'n_estimators': 427, 'learning_rate': 0.015070812984816804, 'max_depth': 5, 'lambda_l1': 0.653880416824309, 'lambda_l2': 1.4283696920817953e-06, 'num_leaves': 474, 'min_data_in_leaf': 143, 'min_gain_to_split': 0.2747888508081174, 'feature_fraction': 0.8058706555447173, 'bagging_fraction': 0.592086055005556, 'bagging_freq': 5, 'max_bin': 250}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:54:42,547] Trial 27 finished with value: 0.49111120307773737 and parameters: {'n_estimators': 437, 'learning_rate': 0.013809931543536153, 'max_depth': 5, 'lambda_l1': 0.023578150714728015, 'lambda_l2': 2.6648857549870787e-06, 'num_leaves': 469, 'min_data_in_leaf': 151, 'min_gain_to_split': 0.29445316910826314, 'feature_fraction': 0.7154838149815066, 'bagging_fraction': 0.6082948806799277, 'bagging_freq': 5, 'max_bin': 255}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:54:43,504] Trial 28 finished with value: 0.4872022061310295 and parameters: {'n_estimators': 453, 'learning_rate': 0.016052593536455752, 'max_depth': 5, 'lambda_l1': 0.0015255852301836019, 'lambda_l2': 1.0473349935773685e-06, 'num_leaves': 470, 'min_data_in_leaf': 170, 'min_gain_to_split': 0.2873980021286807, 'feature_fraction': 0.7780215803541364, 'bagging_fraction': 0.6089492718140543, 'bagging_freq': 5, 'max_bin': 255}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:54:44,785] Trial 29 finished with value: 0.49010440585406134 and parameters: {'n_estimators': 575, 'learning_rate': 0.013518057297572286, 'max_depth': 5, 'lambda_l1': 0.01965012316521049, 'lambda_l2': 2.496202533575519e-06, 'num_leaves': 404, 'min_data_in_leaf': 143, 'min_gain_to_split': 0.14540959876197823, 'feature_fraction': 0.7172609993712056, 'bagging_fraction': 0.6743490825548966, 'bagging_freq': 6, 'max_bin': 227}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:54:46,019] Trial 30 finished with value: 0.4672625510711441 and parameters: {'n_estimators': 558, 'learning_rate': 0.0649162220467436, 'max_depth': 5, 'lambda_l1': 0.018337558277603413, 'lambda_l2': 1.259579291386237e-07, 'num_leaves': 469, 'min_data_in_leaf': 162, 'min_gain_to_split': 0.19340088904005018, 'feature_fraction': 0.7964091497626614, 'bagging_fraction': 0.6763984906229635, 'bagging_freq': 6, 'max_bin': 223}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:54:47,505] Trial 31 finished with value: 0.4873265835763032 and parameters: {'n_estimators': 679, 'learning_rate': 0.012376400171073183, 'max_depth': 5, 'lambda_l1': 0.6076580190723293, 'lambda_l2': 2.8481562790298363e-06, 'num_leaves': 410, 'min_data_in_leaf': 144, 'min_gain_to_split': 0.3093369676413984, 'feature_fraction': 0.7008524964270791, 'bagging_fraction': 0.6145162502676107, 'bagging_freq': 5, 'max_bin': 240}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:54:48,194] Trial 32 finished with value: 0.4825680523367235 and parameters: {'n_estimators': 431, 'learning_rate': 0.017489975553057313, 'max_depth': 4, 'lambda_l1': 0.10745937361171355, 'lambda_l2': 2.2032580057988853e-05, 'num_leaves': 474, 'min_data_in_leaf': 186, 'min_gain_to_split': 0.12152911682477677, 'feature_fraction': 0.745890010473112, 'bagging_fraction': 0.6741211057916189, 'bagging_freq': 6, 'max_bin': 255}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:54:49,329] Trial 33 finished with value: 0.4879549084665069 and parameters: {'n_estimators': 501, 'learning_rate': 0.013297800351299646, 'max_depth': 5, 'lambda_l1': 0.017688462101531247, 'lambda_l2': 1.7578724975739826e-06, 'num_leaves': 396, 'min_data_in_leaf': 142, 'min_gain_to_split': 0.17349552049555067, 'feature_fraction': 0.7269964849090558, 'bagging_fraction': 0.5681906080278795, 'bagging_freq': 5, 'max_bin': 229}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:54:50,208] Trial 34 finished with value: 0.4824140824044705 and parameters: {'n_estimators': 545, 'learning_rate': 0.01918435285315942, 'max_depth': 4, 'lambda_l1': 1.9744989192438498, 'lambda_l2': 6.593121146350612e-08, 'num_leaves': 446, 'min_data_in_leaf': 164, 'min_gain_to_split': 0.07978332191101917, 'feature_fraction': 0.6635066360039316, 'bagging_fraction': 0.6494772678869251, 'bagging_freq': 6, 'max_bin': 213}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:54:51,294] Trial 35 finished with value: 0.4888232662510963 and parameters: {'n_estimators': 355, 'learning_rate': 0.023799136058120722, 'max_depth': 6, 'lambda_l1': 0.002225681524905365, 'lambda_l2': 4.838952250027101e-07, 'num_leaves': 488, 'min_data_in_leaf': 148, 'min_gain_to_split': 0.009477661240558932, 'feature_fraction': 0.7237545910932852, 'bagging_fraction': 0.7499333326788978, 'bagging_freq': 4, 'max_bin': 242}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:54:52,171] Trial 36 finished with value: 0.4864061904812762 and parameters: {'n_estimators': 380, 'learning_rate': 0.01624359575603182, 'max_depth': 5, 'lambda_l1': 1.3893082648557056, 'lambda_l2': 7.294942808465885e-06, 'num_leaves': 447, 'min_data_in_leaf': 133, 'min_gain_to_split': 0.34214490765430694, 'feature_fraction': 0.7811813179221141, 'bagging_fraction': 0.5544499196102636, 'bagging_freq': 7, 'max_bin': 196}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:54:53,216] Trial 37 finished with value: 0.4849750562776418 and parameters: {'n_estimators': 647, 'learning_rate': 0.012263908816360152, 'max_depth': 4, 'lambda_l1': 0.13183471372194375, 'lambda_l2': 2.2898168124908123e-05, 'num_leaves': 511, 'min_data_in_leaf': 190, 'min_gain_to_split': 0.22237245849720594, 'feature_fraction': 0.6429141358284671, 'bagging_fraction': 0.6041466124866222, 'bagging_freq': 8, 'max_bin': 246}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:54:54,820] Trial 38 finished with value: 0.4726184945478622 and parameters: {'n_estimators': 517, 'learning_rate': 0.03570487632040764, 'max_depth': 6, 'lambda_l1': 0.033136382490486324, 'lambda_l2': 3.2417099829238285e-07, 'num_leaves': 396, 'min_data_in_leaf': 115, 'min_gain_to_split': 0.13058033364978072, 'feature_fraction': 0.882180277999705, 'bagging_fraction': 0.5402438241933192, 'bagging_freq': 5, 'max_bin': 156}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:54:55,451] Trial 39 finished with value: 0.45265006283397247 and parameters: {'n_estimators': 278, 'learning_rate': 0.1512630366008308, 'max_depth': 5, 'lambda_l1': 0.006496700962190222, 'lambda_l2': 0.0005094277954430114, 'num_leaves': 424, 'min_data_in_leaf': 152, 'min_gain_to_split': 0.36881859368529724, 'feature_fraction': 0.701576501768327, 'bagging_fraction': 0.7078312648160461, 'bagging_freq': 3, 'max_bin': 185}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:54:56,121] Trial 40 finished with value: 0.4848837868178002 and parameters: {'n_estimators': 409, 'learning_rate': 0.020625650637069528, 'max_depth': 4, 'lambda_l1': 0.0012502883186439656, 'lambda_l2': 6.287390652886601e-08, 'num_leaves': 455, 'min_data_in_leaf': 164, 'min_gain_to_split': 0.25381677221718213, 'feature_fraction': 0.7457809149452785, 'bagging_fraction': 0.6290768061299575, 'bagging_freq': 4, 'max_bin': 32}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:54:57,439] Trial 41 finished with value: 0.4882849796546087 and parameters: {'n_estimators': 366, 'learning_rate': 0.011923790129669794, 'max_depth': 6, 'lambda_l1': 6.889385330806818, 'lambda_l2': 5.187671428800419e-06, 'num_leaves': 398, 'min_data_in_leaf': 63, 'min_gain_to_split': 0.42011452875900024, 'feature_fraction': 0.6258739137017344, 'bagging_fraction': 0.6607111178546747, 'bagging_freq': 1, 'max_bin': 228}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:54:58,635] Trial 42 finished with value: 0.48796193946341315 and parameters: {'n_estimators': 463, 'learning_rate': 0.015139102682443714, 'max_depth': 5, 'lambda_l1': 0.23485555110853745, 'lambda_l2': 2.8102266566655566e-05, 'num_leaves': 488, 'min_data_in_leaf': 79, 'min_gain_to_split': 0.4627800235166808, 'feature_fraction': 0.6785005264970957, 'bagging_fraction': 0.5801948100849409, 'bagging_freq': 2, 'max_bin': 206}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:55:01,517] Trial 43 finished with value: 0.48293238850974896 and parameters: {'n_estimators': 569, 'learning_rate': 0.012115307954691491, 'max_depth': 7, 'lambda_l1': 1.596031681773736e-08, 'lambda_l2': 2.0488131509708254e-06, 'num_leaves': 382, 'min_data_in_leaf': 51, 'min_gain_to_split': 0.0735026272929104, 'feature_fraction': 0.7598575353443755, 'bagging_fraction': 0.5300200857765773, 'bagging_freq': 2, 'max_bin': 217}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:55:02,094] Trial 44 finished with value: 0.48913448428082695 and parameters: {'n_estimators': 318, 'learning_rate': 0.017226451651313455, 'max_depth': 4, 'lambda_l1': 1.214199443604134, 'lambda_l2': 6.221201353267983e-07, 'num_leaves': 333, 'min_data_in_leaf': 99, 'min_gain_to_split': 0.32465789167150844, 'feature_fraction': 0.7170453245020717, 'bagging_fraction': 0.7477164427365532, 'bagging_freq': 6, 'max_bin': 232}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:55:02,648] Trial 45 finished with value: 0.4845840942829984 and parameters: {'n_estimators': 307, 'learning_rate': 0.02751748994865044, 'max_depth': 4, 'lambda_l1': 1.212485331373904, 'lambda_l2': 6.80112612435442e-07, 'num_leaves': 342, 'min_data_in_leaf': 101, 'min_gain_to_split': 0.3163650932119384, 'feature_fraction': 0.7213971388937459, 'bagging_fraction': 0.7571639549644057, 'bagging_freq': 6, 'max_bin': 235}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:55:04,077] Trial 46 finished with value: 0.48579109691858413 and parameters: {'n_estimators': 843, 'learning_rate': 0.016407309171092888, 'max_depth': 4, 'lambda_l1': 2.99294618820952, 'lambda_l2': 5.708708962654918e-08, 'num_leaves': 426, 'min_data_in_leaf': 140, 'min_gain_to_split': 0.268818414537363, 'feature_fraction': 0.8021066807410897, 'bagging_fraction': 0.7482279048253859, 'bagging_freq': 5, 'max_bin': 250}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:55:06,233] Trial 47 finished with value: 0.4845872241149545 and parameters: {'n_estimators': 606, 'learning_rate': 0.0182674988769765, 'max_depth': 6, 'lambda_l1': 0.039339233301825635, 'lambda_l2': 8.781273333788482e-06, 'num_leaves': 339, 'min_data_in_leaf': 115, 'min_gain_to_split': 0.17088725654729175, 'feature_fraction': 0.5992797408123514, 'bagging_fraction': 0.8091315178380065, 'bagging_freq': 7, 'max_bin': 223}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:55:07,154] Trial 48 finished with value: 0.48633181618066756 and parameters: {'n_estimators': 410, 'learning_rate': 0.010550649714421835, 'max_depth': 5, 'lambda_l1': 5.286179696876407, 'lambda_l2': 3.7997282599185405e-07, 'num_leaves': 379, 'min_data_in_leaf': 137, 'min_gain_to_split': 0.36233102111045323, 'feature_fraction': 0.7304307420313555, 'bagging_fraction': 0.6280536738442937, 'bagging_freq': 6, 'max_bin': 245}. Best is trial 26 with value: 0.49147146008589093.\n",
      "[I 2025-11-10 20:55:07,889] Trial 49 finished with value: 0.48609704911729823 and parameters: {'n_estimators': 461, 'learning_rate': 0.013922397366522824, 'max_depth': 4, 'lambda_l1': 0.7442774557529093, 'lambda_l2': 1.3187559617548787e-06, 'num_leaves': 155, 'min_data_in_leaf': 173, 'min_gain_to_split': 0.20524411859722505, 'feature_fraction': 0.7626251127398702, 'bagging_fraction': 0.6983457202257259, 'bagging_freq': 5, 'max_bin': 232}. Best is trial 26 with value: 0.49147146008589093.\n"
     ]
    }
   ],
   "source": [
    "study2 = optuna.create_study(direction='maximize')\n",
    "study2.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd4d5ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49147146008589093"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study2.best_trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1c6efdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_study2 = study2.best_params\n",
    "best_params_study2.update({'random_seed':21,'objective': 'binary','metric': 'auc','verbose': -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1718e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LGBMClassifier(**best_params_study2)\n",
    "model.fit(X_train,y_train)\n",
    "y_proba_train = model.predict_proba(X_train)[:, 1]\n",
    "y_proba_valid = model.predict_proba(X_valid)[:, 1]\n",
    "y_proba_test=model.predict_proba(X_test)[:,1]\n",
    "gini_train = 2*roc_auc_score(y_train, y_proba_train)-1\n",
    "gini_valid = 2*roc_auc_score(y_valid, y_proba_valid)-1\n",
    "gini_test = 2*roc_auc_score(y_test, y_proba_test)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "743e8e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6250996041098382"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b03a28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49147146008589093"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b595a92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5003762796842128"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ef6852",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1, 10), \n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 10),  \n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'max_bin': trial.suggest_int('max_bin', 32, 255),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 1, 20), \n",
    "        'random_seed':21,\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5), \n",
    "        'max_delta_step': trial.suggest_float('max_delta_step', 0, 10),\n",
    "        'booster': trial.suggest_categorical('booster', ['gbtree', 'dart']),\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',    \n",
    "    }\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_proba=model.predict_proba(X_valid)[:,1]\n",
    "    auc = roc_auc_score(y_valid, y_proba)\n",
    "    gini = 2 * auc - 1\n",
    "    return gini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c46e3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 20:55:44,559] A new study created in memory with name: no-name-478e5687-10ed-422b-9409-a4e3b44c947e\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [20:55:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 20:55:49,941] Trial 0 finished with value: 0.4907810132230208 and parameters: {'n_estimators': 537, 'learning_rate': 0.01150853747121557, 'max_depth': 9, 'reg_lambda': 4.224130456315874, 'reg_alpha': 9.621555870699327, 'subsample': 0.7536133676851808, 'colsample_bytree': 0.6628604212891396, 'max_bin': 252, 'grow_policy': 'lossguide', 'min_child_weight': 3.808222665199013, 'gamma': 0.18184635766444746, 'max_delta_step': 3.914239846235935, 'booster': 'gbtree'}. Best is trial 0 with value: 0.4907810132230208.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [20:55:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 20:59:07,710] Trial 1 finished with value: 0.482806794731677 and parameters: {'n_estimators': 898, 'learning_rate': 0.1131836829731519, 'max_depth': 8, 'reg_lambda': 2.3321823586078305, 'reg_alpha': 3.1529986612220786, 'subsample': 0.9773723498254381, 'colsample_bytree': 0.6142291159883305, 'max_bin': 37, 'grow_policy': 'lossguide', 'min_child_weight': 9.715331243298428, 'gamma': 2.6413046478857676, 'max_delta_step': 0.10554102282272604, 'booster': 'dart'}. Best is trial 0 with value: 0.4907810132230208.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [20:59:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:01:19,316] Trial 2 finished with value: 0.4742323901710819 and parameters: {'n_estimators': 700, 'learning_rate': 0.16607901706970365, 'max_depth': 7, 'reg_lambda': 4.287988065051026, 'reg_alpha': 3.1377926223031483, 'subsample': 0.6950111331079418, 'colsample_bytree': 0.8932992448816169, 'max_bin': 120, 'grow_policy': 'depthwise', 'min_child_weight': 9.360719319677305, 'gamma': 4.306580779942048, 'max_delta_step': 8.591680590358862, 'booster': 'dart'}. Best is trial 0 with value: 0.4907810132230208.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:01:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:05:44,316] Trial 3 finished with value: 0.48679446764376766 and parameters: {'n_estimators': 970, 'learning_rate': 0.021200556020491586, 'max_depth': 12, 'reg_lambda': 9.199750822622228, 'reg_alpha': 5.247353052558906, 'subsample': 0.8294510202532847, 'colsample_bytree': 0.5477350491900754, 'max_bin': 174, 'grow_policy': 'depthwise', 'min_child_weight': 17.155228322744932, 'gamma': 4.502389187473867, 'max_delta_step': 8.375786365298186, 'booster': 'dart'}. Best is trial 0 with value: 0.4907810132230208.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:05:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:05:48,578] Trial 4 finished with value: 0.47910432219409826 and parameters: {'n_estimators': 733, 'learning_rate': 0.030334839480281067, 'max_depth': 7, 'reg_lambda': 1.9575529985185467, 'reg_alpha': 9.752102777806607, 'subsample': 0.7640631783154237, 'colsample_bytree': 0.7989028982633108, 'max_bin': 108, 'grow_policy': 'lossguide', 'min_child_weight': 10.526143676160853, 'gamma': 0.8325643008673739, 'max_delta_step': 5.712451308372854, 'booster': 'gbtree'}. Best is trial 0 with value: 0.4907810132230208.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:05:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:05:50,206] Trial 5 finished with value: 0.4788105333233652 and parameters: {'n_estimators': 517, 'learning_rate': 0.02863436627658917, 'max_depth': 11, 'reg_lambda': 7.223186446684893, 'reg_alpha': 0.1125971158436167, 'subsample': 0.6328711964277427, 'colsample_bytree': 0.6153574177122801, 'max_bin': 230, 'grow_policy': 'depthwise', 'min_child_weight': 6.834144495339192, 'gamma': 1.7493287913545346, 'max_delta_step': 8.210666594300589, 'booster': 'gbtree'}. Best is trial 0 with value: 0.4907810132230208.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:05:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:10:05,868] Trial 6 finished with value: 0.4761659736536381 and parameters: {'n_estimators': 904, 'learning_rate': 0.040463346705335475, 'max_depth': 12, 'reg_lambda': 7.992328951999735, 'reg_alpha': 6.549233509045865, 'subsample': 0.6910543530431371, 'colsample_bytree': 0.8243953750929708, 'max_bin': 43, 'grow_policy': 'depthwise', 'min_child_weight': 15.76116603078461, 'gamma': 2.376686820277971, 'max_delta_step': 5.869138353833149, 'booster': 'dart'}. Best is trial 0 with value: 0.4907810132230208.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:10:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:10:06,675] Trial 7 finished with value: 0.45490920817328173 and parameters: {'n_estimators': 171, 'learning_rate': 0.1972461461049216, 'max_depth': 6, 'reg_lambda': 5.387155510475966, 'reg_alpha': 6.04317503297713, 'subsample': 0.5783860130629963, 'colsample_bytree': 0.9306409136454621, 'max_bin': 88, 'grow_policy': 'lossguide', 'min_child_weight': 17.977359152802062, 'gamma': 1.180777278552572, 'max_delta_step': 4.017824372001919, 'booster': 'gbtree'}. Best is trial 0 with value: 0.4907810132230208.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:10:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:10:07,987] Trial 8 finished with value: 0.4855245717025216 and parameters: {'n_estimators': 244, 'learning_rate': 0.03696261155902907, 'max_depth': 11, 'reg_lambda': 6.4516507228067805, 'reg_alpha': 7.999295403525005, 'subsample': 0.6867627372216416, 'colsample_bytree': 0.6632551445909743, 'max_bin': 77, 'grow_policy': 'lossguide', 'min_child_weight': 1.3247836346163258, 'gamma': 2.705135407212991, 'max_delta_step': 1.5550836124382295, 'booster': 'gbtree'}. Best is trial 0 with value: 0.4907810132230208.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:10:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:14:04,116] Trial 9 finished with value: 0.43772745423325343 and parameters: {'n_estimators': 791, 'learning_rate': 0.09597041143864969, 'max_depth': 12, 'reg_lambda': 5.198294646583961, 'reg_alpha': 5.020545395613337, 'subsample': 0.8726146011388081, 'colsample_bytree': 0.6677890687492964, 'max_bin': 34, 'grow_policy': 'lossguide', 'min_child_weight': 4.006842617611802, 'gamma': 0.189098302728134, 'max_delta_step': 3.712687441228768, 'booster': 'dart'}. Best is trial 0 with value: 0.4907810132230208.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:14:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:14:05,240] Trial 10 finished with value: 0.48640304581599314 and parameters: {'n_estimators': 449, 'learning_rate': 0.010007459896405212, 'max_depth': 4, 'reg_lambda': 3.6690109731610767, 'reg_alpha': 9.86193967829352, 'subsample': 0.514768909080785, 'colsample_bytree': 0.511982255426045, 'max_bin': 228, 'grow_policy': 'lossguide', 'min_child_weight': 2.628565513465789, 'gamma': 0.04078814245631768, 'max_delta_step': 2.6591030171085848, 'booster': 'gbtree'}. Best is trial 0 with value: 0.4907810132230208.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:14:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:14:47,753] Trial 11 finished with value: 0.48881231925591284 and parameters: {'n_estimators': 365, 'learning_rate': 0.011361174822273595, 'max_depth': 10, 'reg_lambda': 9.72716725192176, 'reg_alpha': 7.963759031323088, 'subsample': 0.8257560923258376, 'colsample_bytree': 0.5116707887013373, 'max_bin': 185, 'grow_policy': 'depthwise', 'min_child_weight': 13.844395467949523, 'gamma': 4.968252109909635, 'max_delta_step': 9.893730149619298, 'booster': 'dart'}. Best is trial 0 with value: 0.4907810132230208.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:14:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:26,761] Trial 12 finished with value: 0.4902269736334648 and parameters: {'n_estimators': 343, 'learning_rate': 0.010113854204966544, 'max_depth': 9, 'reg_lambda': 9.707738621915922, 'reg_alpha': 8.442894250951543, 'subsample': 0.8417253765398308, 'colsample_bytree': 0.7191391410387089, 'max_bin': 178, 'grow_policy': 'depthwise', 'min_child_weight': 13.744858735072352, 'gamma': 3.759433588523451, 'max_delta_step': 9.780019976236131, 'booster': 'dart'}. Best is trial 0 with value: 0.4907810132230208.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:27,683] Trial 13 finished with value: 0.491782025449242 and parameters: {'n_estimators': 324, 'learning_rate': 0.013958842315058291, 'max_depth': 9, 'reg_lambda': 3.6413135614796976, 'reg_alpha': 8.18606203782582, 'subsample': 0.917450232975488, 'colsample_bytree': 0.7261090262742776, 'max_bin': 252, 'grow_policy': 'depthwise', 'min_child_weight': 12.381073274055177, 'gamma': 3.6386462324705087, 'max_delta_step': 6.504792187916019, 'booster': 'gbtree'}. Best is trial 13 with value: 0.491782025449242.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:29,616] Trial 14 finished with value: 0.49072092341612716 and parameters: {'n_estimators': 636, 'learning_rate': 0.019819816861939076, 'max_depth': 9, 'reg_lambda': 3.2147004374778447, 'reg_alpha': 8.664538891381357, 'subsample': 0.9771025408856879, 'colsample_bytree': 0.7558221172997629, 'max_bin': 255, 'grow_policy': 'lossguide', 'min_child_weight': 5.660425685196353, 'gamma': 3.5182822618721876, 'max_delta_step': 6.779062333157075, 'booster': 'gbtree'}. Best is trial 13 with value: 0.491782025449242.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:30,775] Trial 15 finished with value: 0.49007199503498877 and parameters: {'n_estimators': 573, 'learning_rate': 0.015742460636396467, 'max_depth': 9, 'reg_lambda': 1.0313750544933895, 'reg_alpha': 7.228405051952684, 'subsample': 0.8952071254659967, 'colsample_bytree': 0.9898059375810782, 'max_bin': 209, 'grow_policy': 'depthwise', 'min_child_weight': 7.214980568622361, 'gamma': 3.2055084810737573, 'max_delta_step': 4.442160536376416, 'booster': 'gbtree'}. Best is trial 13 with value: 0.491782025449242.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:30,994] Trial 16 finished with value: 0.4857808322564341 and parameters: {'n_estimators': 106, 'learning_rate': 0.06060870031690043, 'max_depth': 5, 'reg_lambda': 4.170297384106236, 'reg_alpha': 9.278263575811126, 'subsample': 0.7622555160455494, 'colsample_bytree': 0.7060438044077557, 'max_bin': 254, 'grow_policy': 'depthwise', 'min_child_weight': 19.91542492984364, 'gamma': 1.7971721789492414, 'max_delta_step': 6.883239335100673, 'booster': 'gbtree'}. Best is trial 13 with value: 0.491782025449242.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:32,785] Trial 17 finished with value: 0.4898843682842111 and parameters: {'n_estimators': 404, 'learning_rate': 0.01589373266114061, 'max_depth': 8, 'reg_lambda': 2.6031774809760693, 'reg_alpha': 3.9712248998852213, 'subsample': 0.9217614429090859, 'colsample_bytree': 0.8289250533963027, 'max_bin': 151, 'grow_policy': 'lossguide', 'min_child_weight': 12.219654958917499, 'gamma': 3.9668565173467707, 'max_delta_step': 2.8110805273078556, 'booster': 'gbtree'}. Best is trial 13 with value: 0.491782025449242.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:33,858] Trial 18 finished with value: 0.4843717997097414 and parameters: {'n_estimators': 512, 'learning_rate': 0.05985524673822709, 'max_depth': 10, 'reg_lambda': 4.77707588449094, 'reg_alpha': 6.90801151781139, 'subsample': 0.79684846715894, 'colsample_bytree': 0.5951679281167621, 'max_bin': 208, 'grow_policy': 'lossguide', 'min_child_weight': 8.256768478832651, 'gamma': 3.04410656265629, 'max_delta_step': 5.368173677068928, 'booster': 'gbtree'}. Best is trial 13 with value: 0.491782025449242.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:34,138] Trial 19 finished with value: 0.46733754837147856 and parameters: {'n_estimators': 277, 'learning_rate': 0.2924780718872192, 'max_depth': 7, 'reg_lambda': 6.2848599089428445, 'reg_alpha': 1.039779962673479, 'subsample': 0.9223314289408745, 'colsample_bytree': 0.7764340286925311, 'max_bin': 227, 'grow_policy': 'depthwise', 'min_child_weight': 4.749529168278781, 'gamma': 1.8264543900964996, 'max_delta_step': 6.990980768909457, 'booster': 'gbtree'}. Best is trial 13 with value: 0.491782025449242.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:36,721] Trial 20 finished with value: 0.4887793744370752 and parameters: {'n_estimators': 293, 'learning_rate': 0.015226650480085728, 'max_depth': 10, 'reg_lambda': 3.289891188515591, 'reg_alpha': 8.977016381504535, 'subsample': 0.6269289472526184, 'colsample_bytree': 0.6969298709921896, 'max_bin': 151, 'grow_policy': 'lossguide', 'min_child_weight': 12.435853487641548, 'gamma': 0.8150769356536101, 'max_delta_step': 2.8180403386031676, 'booster': 'gbtree'}. Best is trial 13 with value: 0.491782025449242.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:38,415] Trial 21 finished with value: 0.49105540010229065 and parameters: {'n_estimators': 628, 'learning_rate': 0.022290746049132514, 'max_depth': 9, 'reg_lambda': 3.3636669847367098, 'reg_alpha': 8.587845945155632, 'subsample': 0.9988866986758742, 'colsample_bytree': 0.7305173904220265, 'max_bin': 254, 'grow_policy': 'lossguide', 'min_child_weight': 5.489407791571566, 'gamma': 3.323784825801003, 'max_delta_step': 6.838441442865518, 'booster': 'gbtree'}. Best is trial 13 with value: 0.491782025449242.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:40,294] Trial 22 finished with value: 0.49292856744476365 and parameters: {'n_estimators': 607, 'learning_rate': 0.022588164814314353, 'max_depth': 9, 'reg_lambda': 1.5689581908811814, 'reg_alpha': 7.644251608273446, 'subsample': 0.9478392059059225, 'colsample_bytree': 0.6512488549315196, 'max_bin': 253, 'grow_policy': 'lossguide', 'min_child_weight': 2.80090869351952, 'gamma': 3.388946452472932, 'max_delta_step': 6.35012771455736, 'booster': 'gbtree'}. Best is trial 22 with value: 0.49292856744476365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:42,191] Trial 23 finished with value: 0.49242269166734887 and parameters: {'n_estimators': 633, 'learning_rate': 0.020874924293045105, 'max_depth': 8, 'reg_lambda': 1.0856777671073807, 'reg_alpha': 7.626073118576901, 'subsample': 0.9937020212980194, 'colsample_bytree': 0.7498118366963848, 'max_bin': 207, 'grow_policy': 'lossguide', 'min_child_weight': 1.4310802299775962, 'gamma': 3.3006539194169244, 'max_delta_step': 7.343593338977302, 'booster': 'gbtree'}. Best is trial 22 with value: 0.49292856744476365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:43,032] Trial 24 finished with value: 0.49181944993277527 and parameters: {'n_estimators': 447, 'learning_rate': 0.0465934821875827, 'max_depth': 8, 'reg_lambda': 1.2073284228664787, 'reg_alpha': 7.592024221357613, 'subsample': 0.9348019790644805, 'colsample_bytree': 0.858364996836427, 'max_bin': 199, 'grow_policy': 'lossguide', 'min_child_weight': 1.214497736667545, 'gamma': 4.060164473689481, 'max_delta_step': 7.934753657019108, 'booster': 'gbtree'}. Best is trial 22 with value: 0.49292856744476365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:43,718] Trial 25 finished with value: 0.49361174597749846 and parameters: {'n_estimators': 444, 'learning_rate': 0.04774721642611104, 'max_depth': 6, 'reg_lambda': 1.0611578010963918, 'reg_alpha': 5.872052279352348, 'subsample': 0.9559361184692791, 'colsample_bytree': 0.8980156668348108, 'max_bin': 202, 'grow_policy': 'lossguide', 'min_child_weight': 1.043131246004981, 'gamma': 3.9710325007538994, 'max_delta_step': 7.767893563312689, 'booster': 'gbtree'}. Best is trial 25 with value: 0.49361174597749846.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:44,333] Trial 26 finished with value: 0.48752775315445507 and parameters: {'n_estimators': 762, 'learning_rate': 0.07993863543064508, 'max_depth': 6, 'reg_lambda': 1.7970528372028447, 'reg_alpha': 5.898701329111276, 'subsample': 0.977464872722049, 'colsample_bytree': 0.9815774873710168, 'max_bin': 233, 'grow_policy': 'lossguide', 'min_child_weight': 2.5396017215678097, 'gamma': 4.729361931767486, 'max_delta_step': 7.71895040915874, 'booster': 'gbtree'}. Best is trial 25 with value: 0.49361174597749846.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:45,832] Trial 27 finished with value: 0.4910001014599552 and parameters: {'n_estimators': 627, 'learning_rate': 0.030928317369813062, 'max_depth': 6, 'reg_lambda': 1.474969921146984, 'reg_alpha': 4.386260027267953, 'subsample': 0.8713435889974296, 'colsample_bytree': 0.9333185349841786, 'max_bin': 197, 'grow_policy': 'lossguide', 'min_child_weight': 2.578500257637609, 'gamma': 2.9190560034130044, 'max_delta_step': 9.192470641189505, 'booster': 'gbtree'}. Best is trial 25 with value: 0.49361174597749846.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:47,001] Trial 28 finished with value: 0.4865116702681984 and parameters: {'n_estimators': 690, 'learning_rate': 0.023094109133845245, 'max_depth': 4, 'reg_lambda': 2.6666264635507826, 'reg_alpha': 6.341729403995746, 'subsample': 0.9486012767631608, 'colsample_bytree': 0.7771519024759234, 'max_bin': 165, 'grow_policy': 'lossguide', 'min_child_weight': 1.037780403466913, 'gamma': 2.222282354939612, 'max_delta_step': 7.512226352119946, 'booster': 'gbtree'}. Best is trial 25 with value: 0.49361174597749846.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:47,702] Trial 29 finished with value: 0.4884748462377344 and parameters: {'n_estimators': 829, 'learning_rate': 0.047994945899534736, 'max_depth': 5, 'reg_lambda': 2.0550967552909194, 'reg_alpha': 7.2502211924359345, 'subsample': 0.9996524247486714, 'colsample_bytree': 0.8697685233552161, 'max_bin': 217, 'grow_policy': 'lossguide', 'min_child_weight': 3.422960883661437, 'gamma': 4.1235574652027, 'max_delta_step': 6.231839639221588, 'booster': 'gbtree'}. Best is trial 25 with value: 0.49361174597749846.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:48,813] Trial 30 finished with value: 0.49026643028277084 and parameters: {'n_estimators': 565, 'learning_rate': 0.03617995683549609, 'max_depth': 7, 'reg_lambda': 1.0601739121289206, 'reg_alpha': 5.252420076253221, 'subsample': 0.9576876598360053, 'colsample_bytree': 0.6419953377269956, 'max_bin': 132, 'grow_policy': 'lossguide', 'min_child_weight': 3.959866847610441, 'gamma': 3.3910012251710855, 'max_delta_step': 4.823437525689692, 'booster': 'gbtree'}. Best is trial 25 with value: 0.49361174597749846.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:49,655] Trial 31 finished with value: 0.4944831742607365 and parameters: {'n_estimators': 458, 'learning_rate': 0.049966173437746904, 'max_depth': 8, 'reg_lambda': 1.5553272529148525, 'reg_alpha': 7.56477507073094, 'subsample': 0.9409877400616095, 'colsample_bytree': 0.8497702372320369, 'max_bin': 188, 'grow_policy': 'lossguide', 'min_child_weight': 1.012765438190356, 'gamma': 3.8858034866332773, 'max_delta_step': 7.662684293171354, 'booster': 'gbtree'}. Best is trial 31 with value: 0.4944831742607365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:50,370] Trial 32 finished with value: 0.49042575504600094 and parameters: {'n_estimators': 461, 'learning_rate': 0.06931976017131727, 'max_depth': 8, 'reg_lambda': 2.5955985533028265, 'reg_alpha': 6.827123782020675, 'subsample': 0.8751780517539797, 'colsample_bytree': 0.9212982088193628, 'max_bin': 191, 'grow_policy': 'lossguide', 'min_child_weight': 2.20399891351174, 'gamma': 3.8363399101707465, 'max_delta_step': 9.152453938763056, 'booster': 'gbtree'}. Best is trial 31 with value: 0.4944831742607365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:51,414] Trial 33 finished with value: 0.4907064312558371 and parameters: {'n_estimators': 498, 'learning_rate': 0.026374786015044747, 'max_depth': 7, 'reg_lambda': 1.7764629964654945, 'reg_alpha': 7.551976266747731, 'subsample': 0.9609616007775026, 'colsample_bytree': 0.8875331967615046, 'max_bin': 164, 'grow_policy': 'lossguide', 'min_child_weight': 3.355229273309895, 'gamma': 4.373588734752306, 'max_delta_step': 7.485758596732275, 'booster': 'gbtree'}. Best is trial 31 with value: 0.4944831742607365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:52,359] Trial 34 finished with value: 0.48895408136020424 and parameters: {'n_estimators': 583, 'learning_rate': 0.08363790695045069, 'max_depth': 8, 'reg_lambda': 1.550485870170773, 'reg_alpha': 5.542006941759249, 'subsample': 0.9067421230481427, 'colsample_bytree': 0.8353869306523399, 'max_bin': 214, 'grow_policy': 'lossguide', 'min_child_weight': 1.0359324450268246, 'gamma': 2.8130183300246285, 'max_delta_step': 8.822986168818831, 'booster': 'gbtree'}. Best is trial 31 with value: 0.4944831742607365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:15:52,708] Trial 35 finished with value: 0.489099106796393 and parameters: {'n_estimators': 408, 'learning_rate': 0.1251828264660837, 'max_depth': 5, 'reg_lambda': 2.155885470508663, 'reg_alpha': 4.710843336522266, 'subsample': 0.9470203728961549, 'colsample_bytree': 0.5776397786144415, 'max_bin': 239, 'grow_policy': 'lossguide', 'min_child_weight': 4.608517023860865, 'gamma': 4.519934820297001, 'max_delta_step': 5.992520362246022, 'booster': 'gbtree'}. Best is trial 31 with value: 0.4944831742607365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:15:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:18:18,736] Trial 36 finished with value: 0.48904104915527147 and parameters: {'n_estimators': 679, 'learning_rate': 0.04972441613733691, 'max_depth': 10, 'reg_lambda': 2.827564392314798, 'reg_alpha': 2.665751329091933, 'subsample': 0.9726773147073023, 'colsample_bytree': 0.9108194473406631, 'max_bin': 171, 'grow_policy': 'lossguide', 'min_child_weight': 2.1533586183128177, 'gamma': 3.1451132343487127, 'max_delta_step': 7.204698715083431, 'booster': 'dart'}. Best is trial 31 with value: 0.4944831742607365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:18:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:18:20,335] Trial 37 finished with value: 0.4901664981600742 and parameters: {'n_estimators': 542, 'learning_rate': 0.020308010174865433, 'max_depth': 7, 'reg_lambda': 2.187747030749161, 'reg_alpha': 9.248764964725666, 'subsample': 0.8908581017567679, 'colsample_bytree': 0.9610172644671168, 'max_bin': 240, 'grow_policy': 'lossguide', 'min_child_weight': 6.101402567020408, 'gamma': 3.644638053367633, 'max_delta_step': 8.152068198783168, 'booster': 'gbtree'}. Best is trial 31 with value: 0.4944831742607365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:18:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:18:21,084] Trial 38 finished with value: 0.4886232091724545 and parameters: {'n_estimators': 396, 'learning_rate': 0.04103220896426793, 'max_depth': 6, 'reg_lambda': 1.331687233804064, 'reg_alpha': 6.079101521228387, 'subsample': 0.8419437626923941, 'colsample_bytree': 0.7956937932814528, 'max_bin': 220, 'grow_policy': 'lossguide', 'min_child_weight': 8.510111631465012, 'gamma': 4.159741376658942, 'max_delta_step': 8.641219480823096, 'booster': 'gbtree'}. Best is trial 31 with value: 0.4944831742607365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:18:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:19:38,675] Trial 39 finished with value: 0.48942297765388987 and parameters: {'n_estimators': 488, 'learning_rate': 0.03258639204267686, 'max_depth': 8, 'reg_lambda': 4.164616436981789, 'reg_alpha': 6.548025675630801, 'subsample': 0.994478716868904, 'colsample_bytree': 0.8496907917123928, 'max_bin': 200, 'grow_policy': 'lossguide', 'min_child_weight': 3.2429646969006822, 'gamma': 2.53038227291586, 'max_delta_step': 5.118944016718816, 'booster': 'dart'}. Best is trial 31 with value: 0.4944831742607365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:19:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:19:42,416] Trial 40 finished with value: 0.4884664654080886 and parameters: {'n_estimators': 719, 'learning_rate': 0.025154684225545055, 'max_depth': 11, 'reg_lambda': 7.969764186522939, 'reg_alpha': 3.5425883826831592, 'subsample': 0.9401775067640431, 'colsample_bytree': 0.8083906590161583, 'max_bin': 186, 'grow_policy': 'lossguide', 'min_child_weight': 1.8998464328625602, 'gamma': 2.238613129381988, 'max_delta_step': 0.4733512882329016, 'booster': 'gbtree'}. Best is trial 31 with value: 0.4944831742607365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:19:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:19:43,294] Trial 41 finished with value: 0.48967803670833066 and parameters: {'n_estimators': 446, 'learning_rate': 0.043982759584215186, 'max_depth': 8, 'reg_lambda': 1.2511688034477084, 'reg_alpha': 7.67783190415046, 'subsample': 0.930519260882025, 'colsample_bytree': 0.8642080482205078, 'max_bin': 203, 'grow_policy': 'lossguide', 'min_child_weight': 1.1315877425883414, 'gamma': 4.0129120119627295, 'max_delta_step': 8.064344954283678, 'booster': 'gbtree'}. Best is trial 31 with value: 0.4944831742607365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:19:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:19:44,119] Trial 42 finished with value: 0.48700097721957003 and parameters: {'n_estimators': 605, 'learning_rate': 0.0563416008378192, 'max_depth': 8, 'reg_lambda': 1.497083311773255, 'reg_alpha': 7.212110490478465, 'subsample': 0.731156147427975, 'colsample_bytree': 0.8906333795525031, 'max_bin': 193, 'grow_policy': 'lossguide', 'min_child_weight': 1.8065937389918665, 'gamma': 4.5104406484742015, 'max_delta_step': 7.821459069577647, 'booster': 'gbtree'}. Best is trial 31 with value: 0.4944831742607365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:19:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:19:44,675] Trial 43 finished with value: 0.4861893272433626 and parameters: {'n_estimators': 534, 'learning_rate': 0.10939546188979457, 'max_depth': 7, 'reg_lambda': 1.0154656358174536, 'reg_alpha': 7.78995140357364, 'subsample': 0.8043250063262259, 'colsample_bytree': 0.7520466372899793, 'max_bin': 181, 'grow_policy': 'lossguide', 'min_child_weight': 4.440354497112736, 'gamma': 4.243197214350864, 'max_delta_step': 6.3794819776571146, 'booster': 'gbtree'}. Best is trial 31 with value: 0.4944831742607365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:19:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:19:45,571] Trial 44 finished with value: 0.4878095863637819 and parameters: {'n_estimators': 669, 'learning_rate': 0.06820186459953485, 'max_depth': 8, 'reg_lambda': 1.7664739186902771, 'reg_alpha': 6.8003109546475695, 'subsample': 0.8598510464444186, 'colsample_bytree': 0.9525354924111721, 'max_bin': 134, 'grow_policy': 'lossguide', 'min_child_weight': 3.031285818187478, 'gamma': 3.8382085891894633, 'max_delta_step': 8.375892641080572, 'booster': 'gbtree'}. Best is trial 31 with value: 0.4944831742607365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:19:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:20:55,332] Trial 45 finished with value: 0.48932527053021424 and parameters: {'n_estimators': 472, 'learning_rate': 0.03217487741197577, 'max_depth': 9, 'reg_lambda': 2.3940296484535546, 'reg_alpha': 5.682551370573746, 'subsample': 0.8954268909669039, 'colsample_bytree': 0.6264928456542758, 'max_bin': 99, 'grow_policy': 'lossguide', 'min_child_weight': 1.7631918265926605, 'gamma': 4.779399464660928, 'max_delta_step': 5.479043917423391, 'booster': 'dart'}. Best is trial 31 with value: 0.4944831742607365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:20:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:20:57,306] Trial 46 finished with value: 0.48881154792291914 and parameters: {'n_estimators': 428, 'learning_rate': 0.017608366525951095, 'max_depth': 10, 'reg_lambda': 2.93138333736352, 'reg_alpha': 8.172549786170425, 'subsample': 0.9631795139949492, 'colsample_bytree': 0.8483318946527301, 'max_bin': 57, 'grow_policy': 'lossguide', 'min_child_weight': 5.003766348903104, 'gamma': 3.4662567054994087, 'max_delta_step': 7.296702348444165, 'booster': 'gbtree'}. Best is trial 31 with value: 0.4944831742607365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:20:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:20:59,665] Trial 47 finished with value: 0.4922738243995173 and parameters: {'n_estimators': 361, 'learning_rate': 0.01262062709540337, 'max_depth': 9, 'reg_lambda': 2.05899569521784, 'reg_alpha': 7.435586153038979, 'subsample': 0.9365384079132246, 'colsample_bytree': 0.6753418616306798, 'max_bin': 240, 'grow_policy': 'lossguide', 'min_child_weight': 3.701717178725751, 'gamma': 3.6489706170576484, 'max_delta_step': 6.066040813197423, 'booster': 'gbtree'}. Best is trial 31 with value: 0.4944831742607365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:20:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:21:01,557] Trial 48 finished with value: 0.4915330332254655 and parameters: {'n_estimators': 203, 'learning_rate': 0.012461156309754098, 'max_depth': 9, 'reg_lambda': 1.9916283331770885, 'reg_alpha': 6.386825963374346, 'subsample': 0.9804324183808295, 'colsample_bytree': 0.6840358500497477, 'max_bin': 234, 'grow_policy': 'lossguide', 'min_child_weight': 10.368119734837503, 'gamma': 3.0265695535928305, 'max_delta_step': 5.850132568190135, 'booster': 'gbtree'}. Best is trial 31 with value: 0.4944831742607365.\n",
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:21:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-10 21:21:45,132] Trial 49 finished with value: 0.4934186012291488 and parameters: {'n_estimators': 355, 'learning_rate': 0.013451843942322399, 'max_depth': 9, 'reg_lambda': 2.3331056677630384, 'reg_alpha': 8.875285083574, 'subsample': 0.8944306636157298, 'colsample_bytree': 0.6406855062038087, 'max_bin': 244, 'grow_policy': 'lossguide', 'min_child_weight': 6.793763443622504, 'gamma': 3.6061594450652494, 'max_delta_step': 6.4528953494530334, 'booster': 'dart'}. Best is trial 31 with value: 0.4944831742607365.\n"
     ]
    }
   ],
   "source": [
    "study3 = optuna.create_study(direction='maximize')\n",
    "study3.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e58f7adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4944831742607365"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study3.best_trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a09921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_study3 = study3.best_params\n",
    "best_params_study3.update({'random_seed':21,'objective': 'binary:logistic','eval_metric': 'auc','verbose': -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3219ef28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daughtor/ml/.venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [21:25:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"random_seed\", \"verbose\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "model=XGBClassifier(**best_params_study3)\n",
    "model.fit(X_train,y_train)\n",
    "y_proba_train = model.predict_proba(X_train)[:, 1]\n",
    "y_proba_valid = model.predict_proba(X_valid)[:, 1]\n",
    "y_proba_test=model.predict_proba(X_test)[:,1]\n",
    "gini_train = 2*roc_auc_score(y_train, y_proba_train)-1\n",
    "gini_valid = 2*roc_auc_score(y_valid, y_proba_valid)-1\n",
    "gini_test = 2*roc_auc_score(y_test, y_proba_test)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b54f5633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6517914868697137"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97cb12d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4944831742607365"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55b621d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4731420178690664"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a00155",
   "metadata": {},
   "source": [
    "### CatBoost показал минимальное преимущество благодаря встроенной обработке категориальных признаков, однако XGBoost продемонстрировал сравнимую точность за счет надежного level-wise роста деревьев, обеспечивающего стабильность. LightGBM также показал конкурентные результаты, компенсируя потенциальную склонность к переобучению исключительной скоростью работы и эффективным использованием памяти.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b425f19",
   "metadata": {},
   "source": [
    "## 9. Implement the ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377bfc3f",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier (Extremely Randomized Trees) — это ансамблевый метод, который использует максимально рандомизированные деревья решений для повышения разнообразия и уменьшения переобучения.\n",
    "### Суть метода:\n",
    "- Каждое дерево строится на всей выборке\n",
    "- Разбиения выбираются случайно: случайный признак, случайный порог\n",
    "- Из всех случайных разбиений выбирается лучшее\n",
    "### Алгоритм:\n",
    "- Для каждого узла случайно выбирается подмножество признаков\n",
    "- Для каждого выбранного признака генерируется случайный порог разбиения\n",
    "- Из всех случайных кандидатов выбирается лучшее разбиение\n",
    "### Плюсы:\n",
    "- Высокая скорость обучения (нет поиска оптимальных разбиений)\n",
    "- Меньшая вероятность переобучения\n",
    "- Меньшая чувствительность к шуму\n",
    "- Эффективен на данных с большим количеством признаков\n",
    "### Минусы:\n",
    "- Может проигрывать в точности на малых выборках\n",
    "- Сильная зависимость от числа деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9ebf4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_ExtraTreesClassifier:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, min_samples_split=2, \n",
    "                 random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.estimators_ = []\n",
    "        self.n_classes_ = None\n",
    "        self.random_state=random_state\n",
    "        self.rng = np.random.RandomState(self.random_state)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        self.n_classes_ = len(np.unique(y))\n",
    "        self.estimators_ = []\n",
    "        for i in range(self.n_estimators):\n",
    "            tree = my_DecisionTreeClassifierRand(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                random_state=self.rng.randint(0, 1000)\n",
    "            )\n",
    "            n_samples = X.shape[0]\n",
    "            indices = self.rng.choice(n_samples, size=n_samples, replace=True)\n",
    "            X_bootstrap = X[indices]\n",
    "            y_bootstrap = y[indices]\n",
    "            tree.fit(X_bootstrap, y_bootstrap)\n",
    "            self.estimators_.append(tree)   \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = np.array(X)\n",
    "        all_proba = []\n",
    "        for tree in self.estimators_:\n",
    "            tree_proba = tree.predict_proba(X)\n",
    "            all_proba.append(tree_proba)\n",
    "        proba = np.mean(all_proba, axis=0)\n",
    "        return proba\n",
    "    \n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return np.argmax(proba, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6a60c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4637754732721251"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = my_ExtraTreesClassifier(n_estimators=10, max_depth=7,random_state=21,min_samples_split=2)\n",
    "model.fit(X_train,y_train)\n",
    "y_proba=model.predict_proba(X_valid)[:,1]\n",
    "auc = roc_auc_score(y_valid, y_proba)\n",
    "gini = 2 * auc - 1\n",
    "gini\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
